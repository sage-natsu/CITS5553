{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "To use this file for testing, please upload files in the email as follows:-\n",
        "1. [Audio Emotional Analysis] Do not need files.\n",
        "2. [Text Sentiment Analysis] Do not need files.\n",
        "3. [Contextual Coherence Model] Create a folder named 'coherence_model' in content folder, extract and upload files in coherence_model folder.\n",
        "4. Upload testing file and rename it in main pipeline (ie dialogue1.txt)"
      ],
      "metadata": {
        "id": "woqBdoivZg_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use this file for training:\n",
        "\n",
        "\n",
        "1.   [Audio Emotional Analysis] Do not need training.\n",
        "2.   [Text  Sentiment Analysis] Do not need training.\n",
        "3.   [Contextual Coherence Analysis] upload 'dialogues_dataset.csv' (contextual coherence analysis dataset) in content folder, and change main pipeline (change load_model = False)"
      ],
      "metadata": {
        "id": "Ju9oLNzYZfVT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RWHk6WQ-tfp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16cc2e71-6642-4c18-882c-0558a30b8a12",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: torch==2.4.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.4.1+cu121)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (3.1.4)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.1->torchaudio) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.1->torchaudio) (1.3.0)\n",
            "Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.0.1 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets torchaudio librosa pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7FAXa4zKD1A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9628517b-2afb-4f4e-e61f-a6f86b9afb95",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "#For sentiment\n",
        "!pip install transformers datasets torch scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFh07A73-uCe"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForAudioClassification, Wav2Vec2FeatureExtractor\n",
        "import torch\n",
        "import os\n",
        "import librosa\n",
        "import pandas as pd\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, MobileBertForSequenceClassification\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM9k3Ig2UN-i"
      },
      "source": [
        "# Audio Processing For Emotional Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdBQ7hWN-v4k"
      },
      "outputs": [],
      "source": [
        "class PretrainedEmotionModel:\n",
        "    \"\"\"\n",
        "    Use the pre-trained DistilHuBERT model from Hugging Face for emotion classification.\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name):\n",
        "        # Load the pre-trained DistilHuBERT model and feature extractor\n",
        "        self.feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
        "        self.model = AutoModelForAudioClassification.from_pretrained(model_name)\n",
        "\n",
        "    def predict_all_labels(self, audio_file_path):\n",
        "        \"\"\"\n",
        "        Predict all possible emotion labels with their respective confidence scores.\n",
        "        \"\"\"\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Load and preprocess the audio\n",
        "        speech_array, sampling_rate = librosa.load(audio_file_path, sr=16000)\n",
        "        inputs = self.feature_extractor(\n",
        "            speech_array, return_tensors=\"pt\", sampling_rate=sampling_rate, padding=True\n",
        "        )\n",
        "\n",
        "        # Move inputs and model to the appropriate device (GPU or CPU)\n",
        "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "        self.model.to(device)\n",
        "\n",
        "        # Make predictions\n",
        "        with torch.no_grad():\n",
        "            logits = self.model(**inputs).logits\n",
        "            probabilities = torch.softmax(logits, dim=-1).squeeze().cpu().numpy()\n",
        "\n",
        "        # Map label IDs to emotion labels\n",
        "        id2label = self.model.config.id2label\n",
        "\n",
        "        # Collect the predictions and their associated confidence scores\n",
        "        results = []\n",
        "        for label_id, confidence in enumerate(probabilities):\n",
        "            emotion = id2label[label_id]\n",
        "            results.append({\n",
        "                'audio_file': os.path.basename(audio_file_path),\n",
        "                'emotion': emotion.capitalize(),\n",
        "                'confidence': confidence\n",
        "            })\n",
        "\n",
        "        # Sort results by confidence in descending order\n",
        "        df = pd.DataFrame(results)\n",
        "        df = df.sort_values(by='confidence', ascending=False).reset_index(drop=True)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "class EmotionPipeline:\n",
        "    \"\"\"\n",
        "    Orchestrates the workflow of downloading audio data from Google Drive and performing emotion classification.\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name=\"pollner/distilhubert-finetuned-ravdess\"):\n",
        "        self.model_name = model_name\n",
        "        self.model = PretrainedEmotionModel(self.model_name)\n",
        "\n",
        "    def authenticate_and_create_drive(self):\n",
        "        \"\"\"\n",
        "        Authenticates the user and creates a PyDrive GoogleDrive instance.\n",
        "        \"\"\"\n",
        "        auth.authenticate_user()\n",
        "        gauth = GoogleAuth()\n",
        "        gauth.credentials = GoogleCredentials.get_application_default()\n",
        "        drive = GoogleDrive(gauth)\n",
        "        return drive\n",
        "\n",
        "    def download_audio_from_drive(self, drive, audio_file_id, destination_path):\n",
        "        \"\"\"\n",
        "        Downloads an audio file from Google Drive using its file ID.\n",
        "        \"\"\"\n",
        "        print(f\"Downloading audio file from Google Drive with file ID: {audio_file_id}\")\n",
        "        downloaded = drive.CreateFile({'id': audio_file_id})\n",
        "        downloaded.GetContentFile(destination_path)\n",
        "        print(f\"Downloaded audio file and saved as {destination_path}\")\n",
        "\n",
        "    def load_and_predict(self, audio_file_ids):\n",
        "        \"\"\"\n",
        "        Downloads the audio files using their file IDs and predicts all possible labels.\n",
        "        \"\"\"\n",
        "        drive = self.authenticate_and_create_drive()\n",
        "\n",
        "        for audio_file_name, audio_file_id in audio_file_ids.items():\n",
        "            destination_path = f\"./{audio_file_name}\"\n",
        "            self.download_audio_from_drive(drive, audio_file_id, destination_path)\n",
        "\n",
        "            # Perform prediction using the pre-trained model\n",
        "            result_df = self.model.predict_all_labels(destination_path)\n",
        "        return result_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrcT13-sUYZc"
      },
      "source": [
        "# Text Processing with Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTAateS1Ko2U"
      },
      "outputs": [],
      "source": [
        "class TextSentimentAnalysisPipeline:\n",
        "    def __init__(self, dataset_path, model_name='cambridgeltl/sst_mobilebert-uncased'):\n",
        "        with open(dataset_path, 'r') as file:\n",
        "            self.conversation = [line.strip() for line in file.readlines()]\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = MobileBertForSequenceClassification.from_pretrained(model_name)\n",
        "        self.model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    def extract_caller_text(self):\n",
        "        # Extract lines spoken by the \"Caller\"\n",
        "        caller_lines = [line.lstrip('\"Caller: ').rstrip('\", ').split('. ') for line in self.conversation if line.startswith('\"Caller:')]\n",
        "        caller_lines = [sentence for sublist in caller_lines for sentence in sublist]\n",
        "        return caller_lines\n",
        "\n",
        "    def predict_sentiments(self, texts):\n",
        "        inputs = self.tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "        outputs = self.model(**inputs)\n",
        "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "        return probs.detach().numpy()\n",
        "\n",
        "    def evaluate(self):\n",
        "        # Extract all text spoken by the Caller\n",
        "        caller_text = self.extract_caller_text()\n",
        "\n",
        "        # Predict sentiments and get confidence scores\n",
        "        result = []\n",
        "        for turn in caller_text:\n",
        "          prob = self.predict_sentiments(turn)\n",
        "          result.append({\n",
        "              'Sentence': turn,\n",
        "              'Positive Confidence': prob[0, 2],\n",
        "              'Negative Confidence': prob[0, 0],\n",
        "              'Neutral Confidence': prob[0, 1]\n",
        "        })\n",
        "        result_df = pd.DataFrame(result)\n",
        "        avg_pos = result_df['Positive Confidence'].mean()\n",
        "        avg_neg = result_df['Negative Confidence'].mean()\n",
        "        avg_neu = result_df['Neutral Confidence'].mean()\n",
        "        sentiment_df = pd.DataFrame({'sentiment':['Positive', 'Negative', 'Neutral'], 'confidence':[avg_pos, avg_neg, avg_neu]})\n",
        "        return sentiment_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRv9JPKxmEZX"
      },
      "source": [
        "# Contextual Coherence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from transformers import BigBirdForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, DataCollatorWithPadding\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import joblib\n",
        "import os\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "jjWNIdi0746Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDQVoRudbBWG"
      },
      "outputs": [],
      "source": [
        "# Step 1: Class for defining the custom dataset\n",
        "class DialogueDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length):\n",
        "        self.dataframe = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        context = self.dataframe.iloc[idx, 0]\n",
        "        response = self.dataframe.iloc[idx, 1]\n",
        "        label = self.dataframe.iloc[idx, 2]\n",
        "\n",
        "        combined_text = context + \" \" + self.tokenizer.sep_token + \" \" + response\n",
        "        encoding = self.tokenizer(\n",
        "            combined_text,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        input_ids = encoding[\"input_ids\"].squeeze(0)\n",
        "        attention_mask = encoding[\"attention_mask\"].squeeze(0)\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Step 2: Class for model training\n",
        "class ModelTrainer:\n",
        "    def __init__(self, train_dataset):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('google/bigbird-roberta-base')\n",
        "        self.model = BigBirdForSequenceClassification.from_pretrained('google/bigbird-roberta-base')\n",
        "        self.train_dataset = train_dataset\n",
        "        self.training_args = self._setup_training_args()\n",
        "        for name, param in self.model.named_parameters():\n",
        "          if not param.is_contiguous():\n",
        "            #print(f'Making contiguous:{name}')\n",
        "            param.data = param.data.contiguous()\n",
        "        #for name, param in self.model.named_parameters():\n",
        "            #print(f'Layer:{name}, Contiguous:{param.is_contiguous()}')\n",
        "\n",
        "    def _setup_training_args(self):\n",
        "        # Set up training arguments, limiting to 1 epoch for quick testing\n",
        "        return TrainingArguments(\n",
        "            output_dir='./results',\n",
        "            num_train_epochs=1,  # Quick testing with 1 epoch\n",
        "            per_device_train_batch_size=8,\n",
        "            learning_rate=2e-5,\n",
        "            warmup_steps=500,\n",
        "            weight_decay=0.01,\n",
        "            logging_dir='./logs',\n",
        "            logging_steps=50,\n",
        "            save_total_limit=2,\n",
        "            save_steps=200,\n",
        "            evaluation_strategy=\"no\",\n",
        "        )\n",
        "\n",
        "    def fine_tune_model(self):\n",
        "        trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=self.training_args,\n",
        "            train_dataset=self.train_dataset\n",
        "        )\n",
        "        trainer.train()\n",
        "        return self.model\n",
        "\n",
        "    def save_model(self, save_path):\n",
        "        self.model.save_pretrained(save_path)\n",
        "        self.tokenizer.save_pretrained(save_path)\n",
        "        print(f\"Model saved to {save_path}\")\n",
        "\n",
        "# Step 3: Class for coherence evaluation\n",
        "class CoherenceEvaluator:\n",
        "    def __init__(self, model_path):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        self.model = BigBirdForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "    def tokenize_input(self, context, response):\n",
        "        return self.tokenizer(context, response, return_tensors='pt', max_length=1024, truncation=True, padding='max_length')\n",
        "\n",
        "    def compute_logits(self, inputs):\n",
        "        outputs = self.model(**inputs)\n",
        "        return outputs.logits\n",
        "\n",
        "    def apply_softmax(self, logits):\n",
        "        probabilities = F.softmax(logits, dim=1)\n",
        "        return probabilities[0][1].item()\n",
        "\n",
        "# Step 4: Main pipeline class to encapsulate the entire process\n",
        "class CoherencePipeline:\n",
        "    def __init__(self, dataset_path, model_save_path, load_model=False):\n",
        "        self.file_path = dataset_path\n",
        "        self.model_save_path = model_save_path\n",
        "        self.load_model = load_model\n",
        "        self.model_trainer = None\n",
        "        self.coherence_evaluator = None\n",
        "\n",
        "    def prepare_dataset(self):\n",
        "        df = pd.read_csv(self.file_path)\n",
        "        tokenizer = AutoTokenizer.from_pretrained('google/bigbird-roberta-base')\n",
        "        train_dataset = DialogueDataset(df, tokenizer, max_length=256)\n",
        "        return train_dataset\n",
        "\n",
        "    def train_and_save_model(self, train_dataset):\n",
        "        self.model_trainer = ModelTrainer(train_dataset)\n",
        "        trained_model = self.model_trainer.fine_tune_model()\n",
        "        self.model_trainer.save_model(self.model_save_path)\n",
        "        return trained_model\n",
        "\n",
        "    def evaluate_coherence(self):\n",
        "        #file_name = list(self.file_path.keys())[0]\n",
        "        with open(self.file_path, 'r') as file:\n",
        "            dialogue = file.readlines()\n",
        "\n",
        "        self.coherence_evaluator = CoherenceEvaluator(self.model_save_path)\n",
        "        pairs = [(dialogue[i].strip(), dialogue[i + 1].strip()) for i in range(len(dialogue) - 1)]\n",
        "\n",
        "        scores = []\n",
        "        for context, response in pairs:\n",
        "            inputs = self.coherence_evaluator.tokenize_input(context, response)\n",
        "            logits = self.coherence_evaluator.compute_logits(inputs)\n",
        "            score = self.coherence_evaluator.apply_softmax(logits)\n",
        "            scores.append(score)\n",
        "\n",
        "        # Create DataFrame to store results\n",
        "        df_results = pd.DataFrame({\n",
        "            'Pair Number': [f'Pair {i+1}' for i in range(len(pairs))],\n",
        "            'Context': [pair[0] for pair in pairs],\n",
        "            'Response': [pair[1] for pair in pairs],\n",
        "            'Coherence Score': scores\n",
        "        })\n",
        "\n",
        "        # Calculate overall coherence score\n",
        "        overall_score = sum(scores) / len(scores)\n",
        "        df_results.loc['Overall'] = ['', '', 'Overall Coherence Score', overall_score]\n",
        "\n",
        "        return df_results\n",
        "\n",
        "    def run_pipeline(self):\n",
        "        if self.load_model:\n",
        "            # Check if fine-tuned model exists\n",
        "            if self.model_save_path.startswith('google/'):\n",
        "              print(f'Using pretrained model from Hugging Face:{self.model_save_path}')\n",
        "            else:\n",
        "                if not os.path.exists(self.model_save_path):\n",
        "                    raise FileNotFoundError(f\"No fine-tuned model found at {self.model_save_path}. Please train the model first.\")\n",
        "                print(f\"Using existing model from {self.model_save_path}\")\n",
        "        else:\n",
        "            # Train model if flag is set to True\n",
        "            train_dataset = self.prepare_dataset()\n",
        "            self.train_and_save_model(train_dataset)\n",
        "\n",
        "        # Proceed to evaluate test data\n",
        "        df_results = self.evaluate_coherence()\n",
        "        print(df_results)\n",
        "        return df_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xDTQo_nRNez"
      },
      "source": [
        "# Final Calculation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "uqaWXePsNC6W",
        "outputId": "7c82ae1e-7d24-4006-f211-0cbbf47ce25c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Example usage for both variations:\\n\\n# Variation 1: Example DataFrame with emotion, level, and confidence\\ndata_emotion = {\\n    \\'audio_file\\': [\\'audio1.mp3\\', \\'audio1.mp3\\', \\'audio1.mp3\\', \\'audio1.mp3\\'],\\n    \\'emotion\\': [\\'Happiness\\', \\'Anger\\', \\'Neutral\\', \\'Sadness\\'],\\n    \\'level\\': [\\'High\\', \\'Medium\\', \\'Unspecified\\', \\'Low\\'],\\n    \\'confidence\\': [0.6, 0.2, 0.1, 0.1]\\n}\\ndf_emotion = pd.DataFrame(data_emotion)\\n\\n# Variation 2: Example DataFrame with Sentiment, Confidence, and Score\\ndata_sentiment = {\\n    \\'Sentiment\\': [\\'neutral\\', \\'positive\\', \\'negative\\'],\\n    \\'Confidence\\': [0.868819, 0.049960, 0.081221]\\n    #\\'Score\\': [0, 1, -1]\\n}\\ndf_sentiment = pd.DataFrame(data_sentiment)\\n\\n# Calculate the final score for both variations\\nfinal_score_emotion = calculate_final_score(df_emotion)\\nfinal_score_sentiment = calculate_final_score(df_sentiment)\\n\\nprint(f\"Final score (Emotion DataFrame): {final_score_emotion:.2f}\")\\nprint(f\"Final score (Sentiment DataFrame): {final_score_sentiment:.2f}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# import pandas as pd\n",
        "# import math\n",
        "\n",
        "# Function to map emotion to a score\n",
        "def map_emotion_to_score(emotion):\n",
        "    emotion_scores = {\n",
        "        'Happy': 1,\n",
        "        'Neutral': 0,\n",
        "        'Calm': 0,\n",
        "        'Angry': -1,\n",
        "        'Disgust': -1,\n",
        "        'Surprised': -1,\n",
        "        'Fearful': -1,\n",
        "        'Sad': -1}\n",
        "    return emotion_scores.get(emotion, 0)\n",
        "\n",
        "# Function to map sentiment to score\n",
        "def map_sentiment_to_score(sentiment):\n",
        "    sentiment_scores = {'Neutral':0, 'Negative':-1, 'Positive':1}\n",
        "    return sentiment_scores.get(sentiment, 0)\n",
        "\n",
        "# Function to apply sigmoid transformation and scale\n",
        "def sigmoid_transform(x):\n",
        "    x_sigmoid = 1 / (1 + math.exp(-x))\n",
        "    x_scaled = x_sigmoid * 10\n",
        "    return x_scaled\n",
        "\n",
        "# Unified function to calculate the final score from any input format\n",
        "def calculate_sentiment_score(df):\n",
        "    if 'emotion' in df.columns:\n",
        "        # Process DataFrame with emotions\n",
        "        df['score'] = df.apply(lambda row: map_emotion_to_score(row['emotion']), axis=1)\n",
        "        df['weighted_score'] = df['score'] * df['confidence']\n",
        "    elif 'sentiment' in df.columns:\n",
        "        # Process DataFrame with Sentiment, Confidence, and Score\n",
        "        df['score'] = df.apply(lambda row: map_sentiment_to_score(row['sentiment']), axis = 1)\n",
        "        df['weighted_score'] = df['score'] * df['confidence']\n",
        "    else:\n",
        "        raise ValueError(\"DataFrame format not recognized.\")\n",
        "\n",
        "    # Calculate weighted sum of scores\n",
        "    weighted_sum = df['weighted_score'].sum()\n",
        "\n",
        "    # Calculate total confidence\n",
        "    total_confidence = df['confidence'].sum()\n",
        "\n",
        "    # Compute the final raw score\n",
        "    sentiment_score_raw = weighted_sum / total_confidence if total_confidence != 0 else 0\n",
        "\n",
        "    # Apply sigmoid transformation to the final score\n",
        "    sentiment_score = sigmoid_transform(sentiment_score_raw)\n",
        "\n",
        "    return sentiment_score, total_confidence\n",
        "\n",
        "def weighted_score(audio_score, audio_confidence, text_score, text_confidence):\n",
        "    return (audio_score * audio_confidence + text_score * text_confidence) / (audio_confidence + text_confidence)\n",
        "\n",
        "'''\n",
        "# Example usage for both variations:\n",
        "\n",
        "# Variation 1: Example DataFrame with emotion, level, and confidence\n",
        "data_emotion = {\n",
        "    'audio_file': ['audio1.mp3', 'audio1.mp3', 'audio1.mp3', 'audio1.mp3'],\n",
        "    'emotion': ['Happiness', 'Anger', 'Neutral', 'Sadness'],\n",
        "    'level': ['High', 'Medium', 'Unspecified', 'Low'],\n",
        "    'confidence': [0.6, 0.2, 0.1, 0.1]\n",
        "}\n",
        "df_emotion = pd.DataFrame(data_emotion)\n",
        "\n",
        "# Variation 2: Example DataFrame with Sentiment, Confidence, and Score\n",
        "data_sentiment = {\n",
        "    'Sentiment': ['neutral', 'positive', 'negative'],\n",
        "    'Confidence': [0.868819, 0.049960, 0.081221]\n",
        "    #'Score': [0, 1, -1]\n",
        "}\n",
        "df_sentiment = pd.DataFrame(data_sentiment)\n",
        "\n",
        "# Calculate the final score for both variations\n",
        "final_score_emotion = calculate_final_score(df_emotion)\n",
        "final_score_sentiment = calculate_final_score(df_sentiment)\n",
        "\n",
        "print(f\"Final score (Emotion DataFrame): {final_score_emotion:.2f}\")\n",
        "print(f\"Final score (Sentiment DataFrame): {final_score_sentiment:.2f}\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg-9RH3wweMM"
      },
      "source": [
        "# Main Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Md1c21Ju-0bi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "351b2776-1356-4301-b4f4-53c1540538cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at pollner/distilhubert-finetuned-ravdess were not used when initializing HubertForSequenceClassification: ['hubert.encoder.pos_conv_embed.conv.weight_g', 'hubert.encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing HubertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing HubertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at pollner/distilhubert-finetuned-ravdess and are newly initialized: ['hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading audio file from Google Drive with file ID: 108kPpEQeA_6RkQXmmLWDJXQzdiISlm0r\n",
            "Downloaded audio file and saved as ./audio1.mp3\n",
            "   audio_file    emotion  confidence\n",
            "0  audio1.mp3    Neutral    0.606270\n",
            "1  audio1.mp3        Sad    0.158477\n",
            "2  audio1.mp3      Happy    0.151101\n",
            "3  audio1.mp3       Calm    0.070716\n",
            "4  audio1.mp3    Disgust    0.005959\n",
            "5  audio1.mp3      Angry    0.003035\n",
            "6  audio1.mp3  Surprised    0.002574\n",
            "7  audio1.mp3    Fearful    0.001867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  sentiment  confidence\n",
            "0  Positive    0.415585\n",
            "1  Negative    0.193286\n",
            "2   Neutral    0.391129\n",
            "Final score (Emotion DataFrame mingyao): 4.95\n",
            "Final score (Sentiment DataFrame bhavik): 5.55\n",
            "Weighted score for user satisfaction: 5.25\n",
            "Using existing model from ./coherence_model\n",
            "        Pair Number                                            Context  \\\n",
            "0            Pair 1  [\"AI: Hi, my name is Lila. I'm Octivo's AI age...   \n",
            "1            Pair 2  \"Caller: Hey, nice to meet you. My name is Mic...   \n",
            "2            Pair 3  \"AI: Thank you for introducing yourself Michae...   \n",
            "3            Pair 4  \"Caller: Yeah, sure. I'm 27 but I feel like I ...   \n",
            "4            Pair 5  \"AI: I completely understand your hesitation a...   \n",
            "5            Pair 6  \"Caller: Ok, that's fair enough. So I'm earnin...   \n",
            "6            Pair 7  \"AI: Thank you for sharing your income range t...   \n",
            "7            Pair 8  \"Caller: I will retire at around 65 and I woul...   \n",
            "Overall                                                                  \n",
            "\n",
            "                                                  Response  Coherence Score  \n",
            "0        \"Caller: Hey, nice to meet you. My name is Mic...         0.590054  \n",
            "1        \"AI: Thank you for introducing yourself Michae...         0.766010  \n",
            "2        \"Caller: Yeah, sure. I'm 27 but I feel like I ...         0.754133  \n",
            "3        \"AI: I completely understand your hesitation a...         0.769230  \n",
            "4        \"Caller: Ok, that's fair enough. So I'm earnin...         0.767711  \n",
            "5        \"AI: Thank you for sharing your income range t...         0.761523  \n",
            "6        \"Caller: I will retire at around 65 and I woul...         0.762877  \n",
            "7        \"AI: It was an absolute pleasure assisting you...         0.767307  \n",
            "Overall                            Overall Coherence Score         0.742356  \n",
            "Final score: 6.12\n"
          ]
        }
      ],
      "source": [
        "# Main function to run the pipeline\n",
        "def main():\n",
        "\n",
        "  audio_model_name = \"pollner/distilhubert-finetuned-ravdess\"\n",
        "\n",
        "  # Initialize the pipeline with the pre-trained model\n",
        "  emotion_pipeline = EmotionPipeline(model_name=audio_model_name)\n",
        "\n",
        "  # Provide the Google Drive file IDs of the audio files\n",
        "  audio_file_ids = {\n",
        "      'audio1.mp3': '108kPpEQeA_6RkQXmmLWDJXQzdiISlm0r'\n",
        "  }\n",
        "\n",
        "  # Download the audio files and perform emotion prediction\n",
        "  audio_results_df = emotion_pipeline.load_and_predict(audio_file_ids)\n",
        "\n",
        "  # Output the audio results\n",
        "  print(audio_results_df)\n",
        "\n",
        "  # Load sentiment analysis model to predict sentiment and confidence scores\n",
        "  test_data_path = '/content/dialogue1.txt'\n",
        "  pipeline = TextSentimentAnalysisPipeline(test_data_path)\n",
        "  textresults_df = pipeline.evaluate()\n",
        "  print(textresults_df)\n",
        "\n",
        "  final_score_emotion, emotion_confidence = calculate_sentiment_score(audio_results_df)\n",
        "  final_score_sentiment, sentiment_confidence = calculate_sentiment_score(textresults_df)\n",
        "\n",
        "  print(f\"Final score (Emotion DataFrame mingyao): {final_score_emotion:.2f}\")\n",
        "  print(f\"Final score (Sentiment DataFrame bhavik): {final_score_sentiment:.2f}\")\n",
        "\n",
        "  user_satisfaction = weighted_score(final_score_emotion, emotion_confidence, final_score_sentiment, sentiment_confidence)\n",
        "  print(f\"Weighted score for user satisfaction: {user_satisfaction:.2f}\")\n",
        "\n",
        "  coherence_pipeline = CoherencePipeline(\n",
        "    dataset_path = test_data_path, # Change to '/content/dialogues_dataset.csv' if you want to train\n",
        "    model_save_path='./coherence_model', load_model=True)  # Set to False if you want to train\n",
        "  coherence_result = coherence_pipeline.run_pipeline()\n",
        "  coherence_score = coherence_result.loc['Overall', 'Coherence Score']\n",
        "\n",
        "  final_score = 0.6*user_satisfaction+0.4*coherence_score*10\n",
        "  print(f\"Final score: {final_score:.2f}\")\n",
        "\n",
        "  #score = calculate_final_score(emotions, levels, confidences)\n",
        "  #print(f\"Final score: {score:.2f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function to run the pipeline\n",
        "def main():\n",
        "\n",
        "  audio_model_name = \"pollner/distilhubert-finetuned-ravdess\"\n",
        "\n",
        "  # Initialize the pipeline with the pre-trained model\n",
        "  emotion_pipeline = EmotionPipeline(model_name=audio_model_name)\n",
        "\n",
        "  # Provide the Google Drive file IDs of the audio files\n",
        "  audio_file_ids = {\n",
        "      'audio2.mp3': '13O1hKhYl5Uzlb0mIadH5hv5t_zSud664'\n",
        "  }\n",
        "\n",
        "  # Download the audio files and perform emotion prediction\n",
        "  audio_results_df = emotion_pipeline.load_and_predict(audio_file_ids)\n",
        "\n",
        "  # Output the audio results\n",
        "  print(audio_results_df)\n",
        "\n",
        "  # Load sentiment analysis model to predict sentiment and confidence scores\n",
        "  test_data_path = '/content/dialogue2.txt'\n",
        "  pipeline = TextSentimentAnalysisPipeline(test_data_path)\n",
        "  textresults_df = pipeline.evaluate()\n",
        "  print(textresults_df)\n",
        "\n",
        "  final_score_emotion, emotion_confidence = calculate_sentiment_score(audio_results_df)\n",
        "  final_score_sentiment, sentiment_confidence = calculate_sentiment_score(textresults_df)\n",
        "\n",
        "  print(f\"Final score (Emotion DataFrame mingyao): {final_score_emotion:.2f}\")\n",
        "  print(f\"Final score (Sentiment DataFrame bhavik): {final_score_sentiment:.2f}\")\n",
        "\n",
        "  user_satisfaction = weighted_score(final_score_emotion, emotion_confidence, final_score_sentiment, sentiment_confidence)\n",
        "  print(f\"Weighted score for user satisfaction: {user_satisfaction:.2f}\")\n",
        "\n",
        "  coherence_pipeline = CoherencePipeline(\n",
        "    dataset_path = test_data_path, # Change to '/content/dialogues_dataset.csv' if you want to train\n",
        "    model_save_path='./coherence_model', load_model=True)  # Set to False if you want to train\n",
        "  coherence_result = coherence_pipeline.run_pipeline()\n",
        "  coherence_score = coherence_result.loc['Overall', 'Coherence Score']\n",
        "\n",
        "  final_score = 0.6*user_satisfaction+0.4*coherence_score*10\n",
        "  print(f\"Final score: {final_score:.2f}\")\n",
        "\n",
        "  #score = calculate_final_score(emotions, levels, confidences)\n",
        "  #print(f\"Final score: {score:.2f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_304t0YUlW8",
        "outputId": "2318eaad-4814-4dc0-cd3e-a3177374ff7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at pollner/distilhubert-finetuned-ravdess were not used when initializing HubertForSequenceClassification: ['hubert.encoder.pos_conv_embed.conv.weight_g', 'hubert.encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing HubertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing HubertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at pollner/distilhubert-finetuned-ravdess and are newly initialized: ['hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading audio file from Google Drive with file ID: 13O1hKhYl5Uzlb0mIadH5hv5t_zSud664\n",
            "Downloaded audio file and saved as ./audio2.mp3\n",
            "   audio_file    emotion  confidence\n",
            "0  audio2.mp3       Calm    0.949149\n",
            "1  audio2.mp3        Sad    0.038235\n",
            "2  audio2.mp3    Neutral    0.007554\n",
            "3  audio2.mp3    Disgust    0.004204\n",
            "4  audio2.mp3    Fearful    0.000314\n",
            "5  audio2.mp3  Surprised    0.000238\n",
            "6  audio2.mp3      Angry    0.000162\n",
            "7  audio2.mp3      Happy    0.000145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  sentiment  confidence\n",
            "0  Positive    0.234192\n",
            "1  Negative    0.505983\n",
            "2   Neutral    0.259824\n",
            "Final score (Emotion DataFrame mingyao): 4.89\n",
            "Final score (Sentiment DataFrame bhavik): 4.32\n",
            "Weighted score for user satisfaction: 4.61\n",
            "Using existing model from ./coherence_model\n",
            "        Pair Number                                            Context  \\\n",
            "0            Pair 1  [\"AI: Hello, I'm Claire, the receptionist at A...   \n",
            "1            Pair 2  \"Caller: Hi, my name is Michael. I have some i...   \n",
            "2            Pair 3  \"AI: Hi, Michael. I'd like to help you with th...   \n",
            "3            Pair 4  \"Caller: Yes. So my phone number is 0406000. Y...   \n",
            "Overall                                                                  \n",
            "\n",
            "                                                  Response  Coherence Score  \n",
            "0        \"Caller: Hi, my name is Michael. I have some i...         0.593523  \n",
            "1        \"AI: Hi, Michael. I'd like to help you with th...         0.758470  \n",
            "2        \"Caller: Yes. So my phone number is 0406000. Y...         0.736634  \n",
            "3        \"AI: Thank you very much for calling today. I'...         0.460681  \n",
            "Overall                            Overall Coherence Score         0.637327  \n",
            "Final score: 5.31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contextual Coherence (ignore - for record keeping)"
      ],
      "metadata": {
        "id": "xEonGw4qid-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from transformers import BigBirdForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import joblib\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "from google.colab import drive\n",
        "import gc\n",
        "\n",
        "# Step 0: Safely handle mounting Google Drive\n",
        "if not os.path.ismount('/content/drive'):\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "    print(\"Drive mounted successfully.\")\n",
        "else:\n",
        "    print(\"Google Drive is already mounted.\")\n",
        "\n",
        "# Clear cache and collect garbage to free memory\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Step 1: Class for handling file operations and dataset management\n",
        "class DatasetHandler:\n",
        "    def __init__(self, save_directory):\n",
        "        self.save_directory = save_directory\n",
        "        self.train_dataset_file = os.path.join(self.save_directory, 'saved_train_dataset.pkl')\n",
        "        self.dataframe = None\n",
        "\n",
        "    def create_save_directory(self):\n",
        "        if not os.path.exists(self.save_directory):\n",
        "            os.makedirs(self.save_directory)\n",
        "            print(f\"Created directory: {self.save_directory}\")\n",
        "\n",
        "    def load_or_upload_dataset(self):\n",
        "        if not os.path.exists(self.train_dataset_file):\n",
        "            print(\"Training dataset file not found in Google Drive. Please upload the dataset.\")\n",
        "            uploaded = files.upload()\n",
        "            file_name = list(uploaded.keys())[0]\n",
        "            self.dataframe = pd.read_csv(file_name)\n",
        "            joblib.dump(self.dataframe, self.train_dataset_file)\n",
        "            print(f\"Dataset saved to {self.train_dataset_file} in Google Drive.\")\n",
        "        else:\n",
        "            # Load the dataset from Google Drive if it already exists\n",
        "            self.dataframe = joblib.load(self.train_dataset_file)\n",
        "            print(f\"Dataset loaded from {self.train_dataset_file} in Google Drive.\")\n",
        "        return self.dataframe\n",
        "\n",
        "# Step 2: Class for defining the custom dataset\n",
        "class DialogueDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length):\n",
        "        self.dataframe = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        context = self.dataframe.iloc[idx, 0]\n",
        "        response = self.dataframe.iloc[idx, 1]\n",
        "        label = self.dataframe.iloc[idx, 2]\n",
        "\n",
        "        combined_text = context + \" \" + self.tokenizer.sep_token + \" \" + response\n",
        "        encoding = self.tokenizer(\n",
        "            combined_text,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        input_ids = encoding[\"input_ids\"].squeeze(0)\n",
        "        attention_mask = encoding[\"attention_mask\"].squeeze(0)\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Custom Trainer class to handle non-contiguous tensor issue\n",
        "class CustomTrainer(Trainer):\n",
        "    def save_model(self, output_dir=None, _internal_call=False):\n",
        "        # Make all tensors contiguous before saving\n",
        "        for param in self.model.parameters():\n",
        "            param.data = param.data.contiguous()\n",
        "        super().save_model(output_dir, _internal_call=_internal_call)\n",
        "\n",
        "# Step 3: Class for model training\n",
        "class ModelTrainer:\n",
        "    def __init__(self, model_name, train_dataset):\n",
        "        self.model_name = model_name\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "        self.model = BigBirdForSequenceClassification.from_pretrained(self.model_name)\n",
        "        self.train_dataset = train_dataset\n",
        "        self.training_args = self._setup_training_args()\n",
        "\n",
        "    def _setup_training_args(self):\n",
        "        # Set up training arguments, limiting to 1 epoch for quick testing\n",
        "        return TrainingArguments(\n",
        "            output_dir='./results',\n",
        "            num_train_epochs=1,  # Quick testing with 1 epoch\n",
        "            per_device_train_batch_size=2,\n",
        "            learning_rate=2e-5,\n",
        "            warmup_steps=500,\n",
        "            weight_decay=0.01,\n",
        "            logging_dir='./logs',\n",
        "            logging_steps=50,\n",
        "            save_total_limit=2,\n",
        "            save_steps=200,\n",
        "            evaluation_strategy=\"no\",\n",
        "        )\n",
        "\n",
        "    def fine_tune_model(self):\n",
        "        trainer = CustomTrainer(\n",
        "            model=self.model,\n",
        "            args=self.training_args,\n",
        "            train_dataset=self.train_dataset\n",
        "        )\n",
        "        trainer.train()\n",
        "        return self.model\n",
        "\n",
        "    def save_model(self, save_path):\n",
        "        # Ensure all tensors are contiguous before saving\n",
        "        for param in self.model.parameters():\n",
        "            param.data = param.data.contiguous()\n",
        "        self.model.save_pretrained(save_path)\n",
        "        self.tokenizer.save_pretrained(save_path)\n",
        "        print(f\"Model saved to {save_path}\")\n",
        "\n",
        "# Step 4: Class for coherence evaluation with memory management\n",
        "class CoherenceEvaluator:\n",
        "    def __init__(self, model_path):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        self.model = BigBirdForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "        # Move model to CPU to avoid GPU memory issues\n",
        "        device = torch.device('cpu')\n",
        "        self.model = self.model.to(device)\n",
        "\n",
        "    def tokenize_input(self, context, response):\n",
        "        return self.tokenizer(context, response, return_tensors='pt', max_length=1024, truncation=True, padding='max_length')\n",
        "\n",
        "    def compute_logits(self, inputs):\n",
        "        # Move inputs to the same device as the model\n",
        "        inputs = {key: val.to(self.model.device) for key, val in inputs.items()}\n",
        "        outputs = self.model(**inputs)\n",
        "        return outputs.logits\n",
        "\n",
        "    def apply_softmax(self, logits):\n",
        "        probabilities = F.softmax(logits, dim=1)\n",
        "        return probabilities[0][1].item()\n",
        "\n",
        "# Step 5: Main pipeline class to encapsulate the entire process\n",
        "class CoherencePipeline:\n",
        "    def __init__(self, dataset_directory, model_name, model_save_path, train_model=True):\n",
        "        self.dataset_directory = dataset_directory\n",
        "        self.model_name = model_name\n",
        "        self.model_save_path = model_save_path\n",
        "        self.train_model = train_model\n",
        "        self.dataset_handler = DatasetHandler(dataset_directory)\n",
        "        self.model_trainer = None\n",
        "        self.coherence_evaluator = None\n",
        "\n",
        "    def prepare_dataset(self):\n",
        "        self.dataset_handler.create_save_directory()\n",
        "        df = self.dataset_handler.load_or_upload_dataset()\n",
        "        tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "        train_dataset = DialogueDataset(df, tokenizer, max_length=256)\n",
        "        return train_dataset\n",
        "\n",
        "    def train_and_save_model(self, train_dataset):\n",
        "        self.model_trainer = ModelTrainer(self.model_name, train_dataset)\n",
        "        trained_model = self.model_trainer.fine_tune_model()\n",
        "        self.model_trainer.save_model(self.model_save_path)\n",
        "        return trained_model\n",
        "\n",
        "    def evaluate_coherence(self, dialogue_file_path):\n",
        "        print(\"Please upload the test file for evaluation:\")\n",
        "        uploaded = files.upload()\n",
        "        file_name = list(uploaded.keys())[0]\n",
        "        with open(file_name, 'r') as file:\n",
        "            dialogue = file.readlines()\n",
        "\n",
        "        self.coherence_evaluator = CoherenceEvaluator(self.model_save_path)\n",
        "        pairs = [(dialogue[i].strip(), dialogue[i + 1].strip()) for i in range(len(dialogue) - 1)]\n",
        "\n",
        "        scores = []\n",
        "        for context, response in pairs:\n",
        "            inputs = self.coherence_evaluator.tokenize_input(context, response)\n",
        "            logits = self.coherence_evaluator.compute_logits(inputs)\n",
        "            score = self.coherence_evaluator.apply_softmax(logits)\n",
        "            scores.append(score)\n",
        "\n",
        "        # Create DataFrame to store results\n",
        "        df_results = pd.DataFrame({\n",
        "            'Pair Number': [f'Pair {i+1}' for i in range(len(pairs))],\n",
        "            'Context': [pair[0] for pair in pairs],\n",
        "            'Response': [pair[1] for pair in pairs],\n",
        "            'Coherence Score': scores\n",
        "        })\n",
        "\n",
        "        # Calculate overall coherence score\n",
        "        overall_score = sum(scores) / len(scores)\n",
        "        df_results.loc['Overall'] = ['', '', 'Overall Coherence Score', overall_score]\n",
        "\n",
        "        return df_results\n",
        "\n",
        "    def run_pipeline(self):\n",
        "        if self.train_model:\n",
        "            # Train model if flag is set to True\n",
        "            train_dataset = self.prepare_dataset()\n",
        "            self.train_and_save_model(train_dataset)\n",
        "        else:\n",
        "            # Check if using a pretrained model from Hugging Face\n",
        "            if self.model_save_path.startswith(\"google/\"):\n",
        "                print(f\"Using pretrained model from Hugging Face: {self.model_save_path}\")\n",
        "            else:\n",
        "                # Check if fine-tuned model exists locally\n",
        "                if not os.path.exists(self.model_save_path):\n",
        "                    raise FileNotFoundError(f\"No fine-tuned model found at {self.model_save_path}. Please train the model first.\")\n",
        "                print(f\"Using existing model from {self.model_save_path}\")\n",
        "\n",
        "        # Proceed to evaluate test data and get DataFrame\n",
        "        df_results = self.evaluate_coherence('your_dialogue_test_file.txt')\n",
        "        print(df_results)\n",
        "        return df_results\n",
        "\n",
        "# Step 6: Run the pipeline\n",
        "pipeline = CoherencePipeline(\n",
        "    dataset_directory='/content/drive/MyDrive/Coherence_Model',\n",
        "    model_name=\"google/bigbird-roberta-base\",\n",
        "    model_save_path=\"google/bigbird-roberta-base\",  # Pretrained model path\n",
        "    train_model=False  # Set to True if you want to train, False to use existing model\n",
        ")\n",
        "\n",
        "# Run the pipeline\n",
        "df_results = pipeline.run_pipeline()\n"
      ],
      "metadata": {
        "id": "cK_anv60VwXU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860,
          "referenced_widgets": [
            "a5def294af844d56ae51b930ba53acd1",
            "e5633e8810314dafa39c61322ff37567",
            "feb1722b6d964e30aef55fbf2b6d2616",
            "2eb96d1c48224793a4fab7336791cb5e",
            "797266bfa33c44f8b9d5d4d692f8903d",
            "9696c300ca0b4cd6b61679030640f951",
            "847d351df03341939c8839a5b568c09b",
            "9e1c3bd6969a48b69c9693e27c59b69d",
            "e38a4b104ed345e8a8c76650913ecb37",
            "baec247e01244ba4839c8264f3851cf4",
            "8ab2ad5e6d314e4da25c493f8531caa3",
            "1df05f41434940d49dd056909942df69",
            "d12173dea96c464092d3781515fcfe37",
            "895346f9506c4966a47c74b1e8f36b29",
            "aa9fac80f3df4de28dd598e24f843f16",
            "c216aa94cfc14031ab5f9de21890af85",
            "666ec8aa74aa469cb067c1d85343ea41",
            "2313cca4e4fc4cd3bb9aad6017733f9b",
            "9f4475d0c74a460bbc230e96c4585d81",
            "d40592221b434e4baba90beabe03ab97",
            "f879e78d34aa46199002661a9c3d618c",
            "0fd25955e05942f196672bda6d268d13",
            "01d17e6bc70e43fa987f662334184fc8",
            "e2bbc891a4724f0da898c123d7a8d50e",
            "d80994884b8648f3a208b5660ced2c6d",
            "b91bb80f70df462f8a6eaffdd9ad11e2",
            "c72325519618431cb1b2c5e08a3bb28c",
            "52e9b0555f3d4d0d9b3d0d97eeaae118",
            "5c74628ac0964ee6b57a9621cc3803bf",
            "30b560c72709412fb2e523017522eb88",
            "8c0cfd75bf5d4be7a797474ab40f441e",
            "3ef1563cae92437681cbbae7b4b33c28",
            "c86805c8fd7d43c587b547b9726fd9a0",
            "704db5ebc24f44198d77cc09b9669e23",
            "e1f4fc89d0fd41f9bf8573fa84059fc2",
            "4f367185c50c405fb6f8561a50549b55",
            "847d33ebd71a454d8938bc0457c74fb3",
            "94b7c159a3374c72b0e0e24bbb9a8345",
            "a79a28ce690d410b8fccaffd9cdc3e96",
            "253d76e2b6954744abcfcf25a8c2d18e",
            "48c972e27167450588b34ad82854dd9f",
            "471b4733897447aeb1b7a52afc55971f",
            "7d026443bd4e4a01acc0cf57f34479cf",
            "a8b1038686b341fdaa6db9a2461df170",
            "3ec5103d14474809b3dabf462d605fc2",
            "9385ae891a114cbebcad517e20312759",
            "8f7c69f798294c66b8492967b2c62041",
            "9bbc68861f074e4b9337fb6b48ca76d1",
            "64145a4aa0754c52aae89e7163f6f0e7",
            "d3f8ae7c6c1742f48d9f4b1c1ff5f394",
            "cf8f947551c64073945c3bc906c95ab2",
            "067fc824211848a29f85b0ef7a283887",
            "b248350962f0446aab49ad51f3d99dd3",
            "5c05e45064fb4aca9d8aee901c117476",
            "e0a79bb68700458b8039605af12c5197"
          ]
        },
        "outputId": "05ea46a0-8278-4867-d2fe-d892a7d8c5fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Drive mounted successfully.\n",
            "Using pretrained model from Hugging Face: google/bigbird-roberta-base\n",
            "Please upload the test file for evaluation:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-615aeb2e-484d-45bb-b4da-a8e02ca3dc4a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-615aeb2e-484d-45bb-b4da-a8e02ca3dc4a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dialogue1.txt to dialogue1.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5def294af844d56ae51b930ba53acd1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1df05f41434940d49dd056909942df69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/846k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01d17e6bc70e43fa987f662334184fc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/775 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "704db5ebc24f44198d77cc09b9669e23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ec5103d14474809b3dabf462d605fc2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Pair Number                                            Context  \\\n",
            "0            Pair 1  [\"AI: Hi, my name is Lila. I'm Octivo's AI age...   \n",
            "1            Pair 2  \"Caller: Hey, nice to meet you. My name is Mic...   \n",
            "2            Pair 3  \"AI: Thank you for introducing yourself Michae...   \n",
            "3            Pair 4  \"Caller: Yeah, sure. I'm 27 but I feel like I ...   \n",
            "4            Pair 5  \"AI: I completely understand your hesitation a...   \n",
            "5            Pair 6  \"Caller: Ok, that's fair enough. So I'm earnin...   \n",
            "6            Pair 7  \"AI: Thank you for sharing your income range t...   \n",
            "7            Pair 8  \"Caller: I will retire at around 65 and I woul...   \n",
            "Overall                                                                  \n",
            "\n",
            "                                                  Response  Coherence Score  \n",
            "0        \"Caller: Hey, nice to meet you. My name is Mic...         0.566975  \n",
            "1        \"AI: Thank you for introducing yourself Michae...         0.552891  \n",
            "2        \"Caller: Yeah, sure. I'm 27 but I feel like I ...         0.556639  \n",
            "3        \"AI: I completely understand your hesitation a...         0.551340  \n",
            "4        \"Caller: Ok, that's fair enough. So I'm earnin...         0.545934  \n",
            "5        \"AI: Thank you for sharing your income range t...         0.556528  \n",
            "6        \"Caller: I will retire at around 65 and I woul...         0.557095  \n",
            "7        \"AI: It was an absolute pleasure assisting you...         0.550583  \n",
            "Overall                            Overall Coherence Score         0.554748  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fofOcT8RL_K"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xEonGw4qid-0"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a5def294af844d56ae51b930ba53acd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5633e8810314dafa39c61322ff37567",
              "IPY_MODEL_feb1722b6d964e30aef55fbf2b6d2616",
              "IPY_MODEL_2eb96d1c48224793a4fab7336791cb5e"
            ],
            "layout": "IPY_MODEL_797266bfa33c44f8b9d5d4d692f8903d"
          }
        },
        "e5633e8810314dafa39c61322ff37567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9696c300ca0b4cd6b61679030640f951",
            "placeholder": "​",
            "style": "IPY_MODEL_847d351df03341939c8839a5b568c09b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "feb1722b6d964e30aef55fbf2b6d2616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e1c3bd6969a48b69c9693e27c59b69d",
            "max": 1017,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e38a4b104ed345e8a8c76650913ecb37",
            "value": 1017
          }
        },
        "2eb96d1c48224793a4fab7336791cb5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baec247e01244ba4839c8264f3851cf4",
            "placeholder": "​",
            "style": "IPY_MODEL_8ab2ad5e6d314e4da25c493f8531caa3",
            "value": " 1.02k/1.02k [00:00&lt;00:00, 27.7kB/s]"
          }
        },
        "797266bfa33c44f8b9d5d4d692f8903d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9696c300ca0b4cd6b61679030640f951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "847d351df03341939c8839a5b568c09b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e1c3bd6969a48b69c9693e27c59b69d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e38a4b104ed345e8a8c76650913ecb37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "baec247e01244ba4839c8264f3851cf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ab2ad5e6d314e4da25c493f8531caa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1df05f41434940d49dd056909942df69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d12173dea96c464092d3781515fcfe37",
              "IPY_MODEL_895346f9506c4966a47c74b1e8f36b29",
              "IPY_MODEL_aa9fac80f3df4de28dd598e24f843f16"
            ],
            "layout": "IPY_MODEL_c216aa94cfc14031ab5f9de21890af85"
          }
        },
        "d12173dea96c464092d3781515fcfe37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_666ec8aa74aa469cb067c1d85343ea41",
            "placeholder": "​",
            "style": "IPY_MODEL_2313cca4e4fc4cd3bb9aad6017733f9b",
            "value": "config.json: 100%"
          }
        },
        "895346f9506c4966a47c74b1e8f36b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f4475d0c74a460bbc230e96c4585d81",
            "max": 760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d40592221b434e4baba90beabe03ab97",
            "value": 760
          }
        },
        "aa9fac80f3df4de28dd598e24f843f16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f879e78d34aa46199002661a9c3d618c",
            "placeholder": "​",
            "style": "IPY_MODEL_0fd25955e05942f196672bda6d268d13",
            "value": " 760/760 [00:00&lt;00:00, 14.8kB/s]"
          }
        },
        "c216aa94cfc14031ab5f9de21890af85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "666ec8aa74aa469cb067c1d85343ea41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2313cca4e4fc4cd3bb9aad6017733f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f4475d0c74a460bbc230e96c4585d81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d40592221b434e4baba90beabe03ab97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f879e78d34aa46199002661a9c3d618c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fd25955e05942f196672bda6d268d13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01d17e6bc70e43fa987f662334184fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2bbc891a4724f0da898c123d7a8d50e",
              "IPY_MODEL_d80994884b8648f3a208b5660ced2c6d",
              "IPY_MODEL_b91bb80f70df462f8a6eaffdd9ad11e2"
            ],
            "layout": "IPY_MODEL_c72325519618431cb1b2c5e08a3bb28c"
          }
        },
        "e2bbc891a4724f0da898c123d7a8d50e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52e9b0555f3d4d0d9b3d0d97eeaae118",
            "placeholder": "​",
            "style": "IPY_MODEL_5c74628ac0964ee6b57a9621cc3803bf",
            "value": "spiece.model: 100%"
          }
        },
        "d80994884b8648f3a208b5660ced2c6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30b560c72709412fb2e523017522eb88",
            "max": 845731,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c0cfd75bf5d4be7a797474ab40f441e",
            "value": 845731
          }
        },
        "b91bb80f70df462f8a6eaffdd9ad11e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ef1563cae92437681cbbae7b4b33c28",
            "placeholder": "​",
            "style": "IPY_MODEL_c86805c8fd7d43c587b547b9726fd9a0",
            "value": " 846k/846k [00:02&lt;00:00, 325kB/s]"
          }
        },
        "c72325519618431cb1b2c5e08a3bb28c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52e9b0555f3d4d0d9b3d0d97eeaae118": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c74628ac0964ee6b57a9621cc3803bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30b560c72709412fb2e523017522eb88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c0cfd75bf5d4be7a797474ab40f441e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ef1563cae92437681cbbae7b4b33c28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c86805c8fd7d43c587b547b9726fd9a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "704db5ebc24f44198d77cc09b9669e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1f4fc89d0fd41f9bf8573fa84059fc2",
              "IPY_MODEL_4f367185c50c405fb6f8561a50549b55",
              "IPY_MODEL_847d33ebd71a454d8938bc0457c74fb3"
            ],
            "layout": "IPY_MODEL_94b7c159a3374c72b0e0e24bbb9a8345"
          }
        },
        "e1f4fc89d0fd41f9bf8573fa84059fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a79a28ce690d410b8fccaffd9cdc3e96",
            "placeholder": "​",
            "style": "IPY_MODEL_253d76e2b6954744abcfcf25a8c2d18e",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "4f367185c50c405fb6f8561a50549b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48c972e27167450588b34ad82854dd9f",
            "max": 775,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_471b4733897447aeb1b7a52afc55971f",
            "value": 775
          }
        },
        "847d33ebd71a454d8938bc0457c74fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d026443bd4e4a01acc0cf57f34479cf",
            "placeholder": "​",
            "style": "IPY_MODEL_a8b1038686b341fdaa6db9a2461df170",
            "value": " 775/775 [00:00&lt;00:00, 7.10kB/s]"
          }
        },
        "94b7c159a3374c72b0e0e24bbb9a8345": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a79a28ce690d410b8fccaffd9cdc3e96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "253d76e2b6954744abcfcf25a8c2d18e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48c972e27167450588b34ad82854dd9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "471b4733897447aeb1b7a52afc55971f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d026443bd4e4a01acc0cf57f34479cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8b1038686b341fdaa6db9a2461df170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ec5103d14474809b3dabf462d605fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9385ae891a114cbebcad517e20312759",
              "IPY_MODEL_8f7c69f798294c66b8492967b2c62041",
              "IPY_MODEL_9bbc68861f074e4b9337fb6b48ca76d1"
            ],
            "layout": "IPY_MODEL_64145a4aa0754c52aae89e7163f6f0e7"
          }
        },
        "9385ae891a114cbebcad517e20312759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3f8ae7c6c1742f48d9f4b1c1ff5f394",
            "placeholder": "​",
            "style": "IPY_MODEL_cf8f947551c64073945c3bc906c95ab2",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "8f7c69f798294c66b8492967b2c62041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_067fc824211848a29f85b0ef7a283887",
            "max": 512568261,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b248350962f0446aab49ad51f3d99dd3",
            "value": 512568261
          }
        },
        "9bbc68861f074e4b9337fb6b48ca76d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c05e45064fb4aca9d8aee901c117476",
            "placeholder": "​",
            "style": "IPY_MODEL_e0a79bb68700458b8039605af12c5197",
            "value": " 513M/513M [00:27&lt;00:00, 19.7MB/s]"
          }
        },
        "64145a4aa0754c52aae89e7163f6f0e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3f8ae7c6c1742f48d9f4b1c1ff5f394": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf8f947551c64073945c3bc906c95ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "067fc824211848a29f85b0ef7a283887": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b248350962f0446aab49ad51f3d99dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c05e45064fb4aca9d8aee901c117476": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0a79bb68700458b8039605af12c5197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}