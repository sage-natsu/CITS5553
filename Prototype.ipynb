{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "To use this file for testing, please upload files in the email as follows:-\n",
        "1. [Audio Emotional Analysis] Upload 'audio_emotion_classifier.joblib' in content folder.\n",
        "2. [Text Sentiment Analysis] Create a folder named 'sentiment_model' in content folder, extract and upload files in the sentiment_model folder.\n",
        "3. [Contextual Coherence Model] Create a folder named 'coherence_model' in content folder, extract and upload files in coherence_model folder.\n",
        "4. Upload testing file and rename it in main pipeline (ie dialogue1.txt)"
      ],
      "metadata": {
        "id": "woqBdoivZg_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use this file for training:\n",
        "\n",
        "\n",
        "1.   [Audio Emotional Analysis] remove the 'audio_emotion_classifier.joblib' file in the content folder.\n",
        "2.   [Text  Sentiment Analysis] upload 'train.csv' (sentiment analysis dataset) in content folder, and change main pipeline (change load_model = False and run pipeline)\n",
        "3.   [Contextual Coherence Analysis] upload 'dialogues_dataset.csv' (contextual coherence analysis dataset) in content folder, and change main pipeline (change load_model = False)"
      ],
      "metadata": {
        "id": "Ju9oLNzYZfVT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RWHk6WQ-tfp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b3beffd-5916-461d-ab3e-0ef5d93c395a",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opensmile\n",
            "  Downloading opensmile-2.5.0-py3-none-manylinux_2_17_x86_64.whl.metadata (15 kB)\n",
            "Collecting audobject>=0.6.1 (from opensmile)\n",
            "  Downloading audobject-0.7.11-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting audinterface>=0.7.0 (from opensmile)\n",
            "  Downloading audinterface-1.2.2-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting audeer>=1.18.0 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audeer-2.2.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting audformat<2.0.0,>=1.0.1 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audformat-1.3.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting audiofile>=1.3.0 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audiofile-1.5.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting audmath>=1.4.1 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audmath-1.4.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting audresample<2.0.0,>=1.1.0 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audresample-1.3.3-py3-none-manylinux_2_17_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from audobject>=0.6.1->opensmile) (8.5.0)\n",
            "Collecting oyaml (from audobject>=0.6.1->opensmile)\n",
            "  Downloading oyaml-1.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from audobject>=0.6.1->opensmile) (24.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from audeer>=1.18.0->audinterface>=0.7.0->opensmile) (4.66.5)\n",
            "Collecting iso639-lang (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile)\n",
            "  Downloading iso639_lang-2.3.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting iso3166 (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile)\n",
            "  Downloading iso3166-2.1.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pandas>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.1.4)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.10/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (14.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (6.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (1.26.4)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (0.12.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.8.0->audobject>=0.6.1->opensmile) (3.20.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2024.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (1.16.0)\n",
            "Downloading opensmile-2.5.0-py3-none-manylinux_2_17_x86_64.whl (996 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m996.2/996.2 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audinterface-1.2.2-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.7/68.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audobject-0.7.11-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audeer-2.2.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audformat-1.3.1-py3-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.9/150.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audiofile-1.5.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audmath-1.4.1-py3-none-any.whl (23 kB)\n",
            "Downloading audresample-1.3.3-py3-none-manylinux_2_17_x86_64.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.4/138.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n",
            "Downloading iso3166-2.1.1-py3-none-any.whl (9.8 kB)\n",
            "Downloading iso639_lang-2.3.0-py3-none-any.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: oyaml, iso639-lang, iso3166, audresample, audmath, audeer, audobject, audiofile, audformat, audinterface, opensmile\n",
            "Successfully installed audeer-2.2.0 audformat-1.3.1 audinterface-1.2.2 audiofile-1.5.0 audmath-1.4.1 audobject-0.7.11 audresample-1.3.3 iso3166-2.1.1 iso639-lang-2.3.0 opensmile-2.5.0 oyaml-1.0\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.1.4\n",
            "    Uninstalling pandas-2.1.4:\n",
            "      Successfully uninstalled pandas-2.1.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.1.4, but you have pandas 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.2.2\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Git LFS initialized.\n",
            "Cloning into 'CREMA-D'...\n",
            "remote: Enumerating objects: 22501, done.\u001b[K\n",
            "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 22501 (delta 22), reused 57 (delta 13), pack-reused 22428 (from 1)\u001b[K\n",
            "Receiving objects: 100% (22501/22501), 14.82 MiB | 12.68 MiB/s, done.\n",
            "Resolving deltas: 100% (75/75), done.\n",
            "Updating files: 100% (22342/22342), done.\n",
            "warning: Clone succeeded, but checkout failed.\n",
            "You can inspect what was checked out with 'git status'\n",
            "and retry with 'git restore --source=HEAD :/'\n",
            "\n",
            "\n",
            "Exiting because of \"interrupt\" signal.\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install opensmile\n",
        "!pip install --upgrade pandas\n",
        "!pip install xgboost\n",
        "!apt-get install git-lfs\n",
        "!git lfs install\n",
        "!git clone https://github.com/CheyneyComputerScience/CREMA-D.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7FAXa4zKD1A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fbea2f5-40fa-4e2d-eea5-7c0964a02a0a",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.0.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.2 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.0.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "#For sentiment\n",
        "!pip install transformers datasets torch scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFh07A73-uCe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import opensmile\n",
        "import audiofile\n",
        "import joblib\n",
        "import math\n",
        "import torch\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.exceptions import NotFittedError\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth, files\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from transformers import BigBirdTokenizer, BigBirdForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding, AutoTokenizer\n",
        "from datasets import Dataset\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM9k3Ig2UN-i"
      },
      "source": [
        "# Audio Processing For Emotional Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdBQ7hWN-v4k"
      },
      "outputs": [],
      "source": [
        "# AudioProcessor: Handles loading of audio files\n",
        "class AudioProcessor:\n",
        "  \"\"\"\n",
        "  AudioProcessor handles loading of audio files.\n",
        "  It extracts audio signals and sampling rates from audio files.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, file_paths):\n",
        "    self.file_paths = file_paths  # List of audio file paths\n",
        "\n",
        "  def load_audio(self, path):\n",
        "    \"\"\"\n",
        "    Loads an audio file and returns the signal and sampling rate.\n",
        "    \"\"\"\n",
        "    try:\n",
        "      signal, sampling_rate = audiofile.read(path, always_2d=True)\n",
        "    except Exception as e:\n",
        "      print(f\"Error loading {path}: {str(e)}\")\n",
        "      return None, None\n",
        "    return signal, sampling_rate\n",
        "\n",
        "  def batch_load(self):\n",
        "    \"\"\"\n",
        "    Loads all audio files in batch.\n",
        "    Returns a list of tuples containing the audio signals and sampling rates.\n",
        "    \"\"\"\n",
        "    signals = []\n",
        "    for path in self.file_paths:\n",
        "      signal, sampling_rate = self.load_audio(path)\n",
        "      if signal is not None:\n",
        "        signals.append((signal, sampling_rate))\n",
        "    return signals\n",
        "\n",
        "\n",
        "# FeatureExtractor: Uses OpenSmile to extract features from audio\n",
        "class FeatureExtractor:\n",
        "  \"\"\"\n",
        "  Extracts features from audio files using OpenSmile.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    self.smile = opensmile.Smile(\n",
        "        feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
        "        feature_level=opensmile.FeatureLevel.Functionals\n",
        "    )\n",
        "\n",
        "  def extract_features(self, signal, sampling_rate):\n",
        "    \"\"\"\n",
        "    Extracts features from a single audio signal using OpenSmile.\n",
        "    \"\"\"\n",
        "    features = self.smile.process_signal(signal, sampling_rate)\n",
        "    return features\n",
        "\n",
        "  def extract_batch_from_paths(self, paths):\n",
        "    \"\"\"\n",
        "    Extracts features from a list of audio file paths.\n",
        "    \"\"\"\n",
        "    all_features = []\n",
        "    for path in paths:\n",
        "      signal, sampling_rate = audiofile.read(path, always_2d=True)\n",
        "      if signal is not None:\n",
        "        features = self.extract_features(signal, sampling_rate)\n",
        "        all_features.append(features)\n",
        "    return pd.concat(all_features, ignore_index=True)\n",
        "\n",
        "\n",
        "# EmotionClassifier: XGBoost classifier with RandomizedSearchCV for hyperparameter tuning\n",
        "class EmotionClassifier:\n",
        "  \"\"\"\n",
        "  A classifier for predicting emotions using XGBoost with RandomizedSearchCV for faster hyperparameter tuning.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    self.model = XGBClassifier(random_state=42)\n",
        "    self.label_encoder = LabelEncoder()\n",
        "    self.scaler = StandardScaler()\n",
        "    self.is_fitted = False\n",
        "\n",
        "  def train(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    Trains the emotion classifier using scaled features and encoded labels.\n",
        "    Uses RandomizedSearchCV for more comprehensive hyperparameter tuning.\n",
        "    \"\"\"\n",
        "    y_train_encoded = self.label_encoder.fit_transform(y_train)\n",
        "    self.feature_names = X_train.columns\n",
        "    X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "\n",
        "    # Define a hyperparameter grid\n",
        "    param_distributions = {\n",
        "        'n_estimators': [100, 200],\n",
        "        'max_depth': [3, 5],\n",
        "        'learning_rate': [0.01, 0.05, 0.1]\n",
        "    }\n",
        "\n",
        "    # Use RandomizedSearchCV with more iterations\n",
        "    randomized_search = RandomizedSearchCV(\n",
        "        estimator=self.model,\n",
        "        param_distributions=param_distributions,\n",
        "        n_iter=5,\n",
        "        cv=3,\n",
        "        scoring='accuracy',\n",
        "        verbose=2,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    randomized_search.fit(X_train_scaled, y_train_encoded)\n",
        "\n",
        "    # Use the best model from RandomizedSearchCV\n",
        "    self.model = randomized_search.best_estimator_\n",
        "    self.is_fitted = True\n",
        "    print(f\"Best parameters found: {randomized_search.best_params_}\")\n",
        "\n",
        "    # Evaluate cross-validation scores\n",
        "    cv_scores = cross_val_score(self.model, X_train_scaled, y_train_encoded, cv=3, scoring='accuracy')\n",
        "    print(f\"Cross-validation scores: {cv_scores}\")\n",
        "    print(f\"Mean cross-validation score: {np.mean(cv_scores)}\")\n",
        "\n",
        "  def predict(self, X):\n",
        "    \"\"\"\n",
        "    Predicts emotions on new data and returns a list of all possible PredictionResult objects.\n",
        "    \"\"\"\n",
        "    if not self.is_fitted:\n",
        "      raise NotFittedError(\"This EmotionClassifier instance is not fitted yet.\")\n",
        "\n",
        "    if not hasattr(self.label_encoder, 'classes_'):\n",
        "      raise ValueError(\"LabelEncoder is not fitted yet.\")\n",
        "\n",
        "    X = X[self.feature_names]\n",
        "    X_scaled = self.scaler.transform(X)\n",
        "    y_proba = self.model.predict_proba(X_scaled)\n",
        "    y_classes = self.label_encoder.classes_\n",
        "\n",
        "    # Create a list of all emotions, levels, and their corresponding confidence scores\n",
        "    all_predictions = []\n",
        "    for i in range(len(X)):\n",
        "      sorted_indices = np.argsort(-y_proba[i])  # Sort by probability in descending order\n",
        "      predictions_for_sample = []\n",
        "      for idx in sorted_indices:\n",
        "        emotion = y_classes[idx]\n",
        "        prob = y_proba[i][idx]\n",
        "        predictions_for_sample.append(PredictionResult(emotion, prob))\n",
        "      all_predictions.append(predictions_for_sample)\n",
        "\n",
        "    return all_predictions\n",
        "\n",
        "  def predict_top_label(self, X):\n",
        "    \"\"\"\n",
        "    Predicts the top emotion label for each sample.\n",
        "    \"\"\"\n",
        "    X = X[self.feature_names]\n",
        "    X_scaled = self.scaler.transform(X)\n",
        "    y_pred_encoded = self.model.predict(X_scaled)\n",
        "    y_pred = self.label_encoder.inverse_transform(y_pred_encoded)\n",
        "    return y_pred\n",
        "\n",
        "  def save_model(self, filename):\n",
        "    \"\"\"\n",
        "    Saves the trained model and scaler to a file.\n",
        "    \"\"\"\n",
        "    model_data = {\n",
        "        'model': self.model,\n",
        "        'scaler': self.scaler,\n",
        "        'label_encoder': self.label_encoder,\n",
        "        'feature_names': self.feature_names\n",
        "    }\n",
        "    joblib.dump(model_data, filename)\n",
        "    print(f\"Model, scaler, label encoder, and feature names saved to {filename}\")\n",
        "\n",
        "  def load_model(self, filename):\n",
        "    \"\"\"\n",
        "    Loads the model from a file if it exists.\n",
        "    \"\"\"\n",
        "    if os.path.exists(filename):\n",
        "      model_data = joblib.load(filename)\n",
        "      self.model = model_data['model']\n",
        "      self.scaler = model_data['scaler']\n",
        "      self.label_encoder = model_data['label_encoder']\n",
        "      self.feature_names = model_data['feature_names']\n",
        "      self.is_fitted = True\n",
        "      print(\"Model, scaler, label encoder, and feature names loaded successfully.\")\n",
        "    else:\n",
        "      print(\"Model file not found. Training a new model.\")\n",
        "\n",
        "\n",
        "# PredictionResult: Stores emotion classification results\n",
        "class PredictionResult:\n",
        "  \"\"\"\n",
        "  Stores the result of an emotion prediction.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, label, confidence):\n",
        "    self.label = label  # Predicted emotion label\n",
        "    self.confidence = confidence  # Confidence score\n",
        "\n",
        "  def __repr__(self):\n",
        "    \"\"\"\n",
        "    String representation of the prediction result.\n",
        "    \"\"\"\n",
        "    return f\"PredictionResult(label={self.label}, confidence={self.confidence})\"\n",
        "\n",
        "\n",
        "# AudioEmotionDetectionPipeline: Get results\n",
        "class AudioEmotionDetectionPipeline:\n",
        "  \"\"\"\n",
        "  Manages the workflow:\n",
        "  - Extracts features using OpenSmile.\n",
        "  - Trains a model using CREMA-D AudioMP3 files.\n",
        "  - Predicts emotions on new audio files using the trained model.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, file_ids):\n",
        "    self.file_ids = file_ids  # Google Drive audio file IDs\n",
        "    self.processor = None  # To handle audio file processing\n",
        "    self.extractor = FeatureExtractor()  # To extract features from audio\n",
        "    self.classifier = EmotionClassifier()  # Emotion classifier\n",
        "\n",
        "  def load_crema_d_data(self):\n",
        "    \"\"\"\n",
        "    Loads CREMA-D AudioMP3 dataset, extracting file paths, emotion labels, and emotion levels from filenames.\n",
        "    Returns a DataFrame with file paths, combined emotion labels and levels.\n",
        "    \"\"\"\n",
        "    audio_dir = './CREMA-D/AudioMP3'\n",
        "    audio_files = [f for f in os.listdir(audio_dir) if f.endswith('.mp3')]\n",
        "\n",
        "    # Define emotion and level mappings\n",
        "    emotions = {\n",
        "        'ANG': 'Anger',\n",
        "        'DIS': 'Disgust',\n",
        "        'FEA': 'Fear',\n",
        "        'HAP': 'Happiness',\n",
        "        'NEU': 'Neutral',\n",
        "        'SAD': 'Sadness'\n",
        "    }\n",
        "\n",
        "    levels = {\n",
        "        'LO': 'Low',\n",
        "        'MD': 'Medium',\n",
        "        'HI': 'High',\n",
        "        'XX': 'Unspecified'\n",
        "    }\n",
        "\n",
        "    file_paths = []\n",
        "    labels = []\n",
        "\n",
        "    for file in audio_files:\n",
        "      parts = file.split('_')\n",
        "\n",
        "      if len(parts) >= 4:\n",
        "        emotion_code = parts[2]  # The third part is the emotion\n",
        "        level_code = parts[3].replace('.mp3', '')  # Remove the .mp3 extension\n",
        "\n",
        "        if emotion_code in emotions and level_code in levels:\n",
        "          emotion = emotions[emotion_code]\n",
        "          level = levels[level_code]\n",
        "          combined_label = f\"{emotion}_{level}\"  # Combine emotion and level\n",
        "\n",
        "          file_paths.append(os.path.join(audio_dir, file))\n",
        "          labels.append(combined_label)\n",
        "\n",
        "    print(f\"Loaded {len(labels)} labels from the files.\")\n",
        "\n",
        "    return pd.DataFrame({'Path': file_paths, 'Label': labels})\n",
        "\n",
        "  def download_and_extract_features(self):\n",
        "    \"\"\"\n",
        "    Downloads audio files from Google Drive and extracts features.\n",
        "    Returns features and a list of file paths.\n",
        "    \"\"\"\n",
        "    file_paths = self.download_files_from_drive(self.file_ids)\n",
        "    self.processor = AudioProcessor(file_paths)\n",
        "    features = self.extractor.extract_batch_from_paths(file_paths)\n",
        "    return features, file_paths  # Return features and file_paths\n",
        "\n",
        "  def download_files_from_drive(self, file_ids):\n",
        "    \"\"\"\n",
        "    Downloads files from Google Drive using file IDs.\n",
        "    Returns a list of file paths.\n",
        "    \"\"\"\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "\n",
        "    file_paths = []\n",
        "    for filename, file_id in file_ids.items():\n",
        "      downloaded = drive.CreateFile({'id': file_id})\n",
        "      downloaded.GetContentFile(filename)\n",
        "      file_paths.append(filename)\n",
        "      print(f\"{filename} downloaded\")\n",
        "    return file_paths\n",
        "\n",
        "  def train_classifier(self):\n",
        "    \"\"\"\n",
        "    Trains the emotion classifier using CREMA-D dataset.\n",
        "    \"\"\"\n",
        "    crema_d_data = self.load_crema_d_data()\n",
        "\n",
        "    # Check the size of the dataset before splitting\n",
        "    print(f\"Dataset size before splitting: {crema_d_data.shape}\")\n",
        "\n",
        "    if crema_d_data.empty:\n",
        "      print(\"Error: The dataset is empty!\")\n",
        "      return\n",
        "\n",
        "    # Load the model if it exists, otherwise train\n",
        "    self.classifier.load_model('audio_emotion_classifier.joblib')\n",
        "\n",
        "    if not self.classifier.is_fitted:\n",
        "      # If the model is not loaded, we need to train it\n",
        "      X_train, X_test, y_train, y_test = train_test_split(\n",
        "          crema_d_data['Path'], crema_d_data['Label'], test_size=0.2, random_state=42)\n",
        "\n",
        "      X_train_features = self.extractor.extract_batch_from_paths(X_train)\n",
        "      X_test_features = self.extractor.extract_batch_from_paths(X_test)\n",
        "\n",
        "      self.classifier.train(X_train_features, y_train)\n",
        "\n",
        "      # Save the trained model\n",
        "      self.classifier.save_model('audio_emotion_classifier.joblib')\n",
        "\n",
        "      # Evaluate model performance\n",
        "      y_test_pred = self.classifier.predict_top_label(X_test_features)\n",
        "      print(\"Model evaluation on test set:\")\n",
        "      print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "      cm = confusion_matrix(y_test, y_test_pred)\n",
        "      print(\"Confusion Matrix:\")\n",
        "      print(cm)\n",
        "\n",
        "  def run(self):\n",
        "    \"\"\"\n",
        "    Runs the entire pipeline and returns predictions for multiple audio files.\n",
        "    \"\"\"\n",
        "    # Train classifier and predict on new audio files\n",
        "    self.train_classifier()\n",
        "    audio_features, file_paths = self.download_and_extract_features()\n",
        "\n",
        "    # Predict on new audio files\n",
        "    all_predictions = self.classifier.predict(audio_features)\n",
        "\n",
        "    # Prepare DataFrame for all predictions with audio file reference\n",
        "    results = []\n",
        "    for i, sample_predictions in enumerate(all_predictions):\n",
        "      # Get the corresponding audio file name for this sample\n",
        "      audio_file = os.path.basename(file_paths[i])  # Get file name\n",
        "      for pred in sample_predictions:\n",
        "        emotion, level = pred.label.split('_')\n",
        "        results.append({\n",
        "            \"audio_file\": audio_file,\n",
        "            \"emotion\": emotion,\n",
        "            \"level\": level,\n",
        "            \"confidence\": pred.confidence\n",
        "        })\n",
        "    return pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrcT13-sUYZc"
      },
      "source": [
        "# Text Processing with Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c21fKDD-KOmo"
      },
      "outputs": [],
      "source": [
        "#For sentiment\n",
        "# import pandas as pd\n",
        "# import torch\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from transformers import BigBirdTokenizer, BigBirdForSequenceClassification, Trainer, TrainingArguments\n",
        "# from transformers import DataCollatorWithPadding\n",
        "# from datasets import Dataset\n",
        "# from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "# import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTAateS1Ko2U"
      },
      "outputs": [],
      "source": [
        "#For sentiment\n",
        "\n",
        "\n",
        "# Main class that encapsulates all functionalities\n",
        "class TextSentimentAnalysisPipeline:\n",
        "    def __init__(self, dataset_path=None, sample_fraction=0.03, load_model=False):\n",
        "        # Load the dataset\n",
        "        self.file_path = dataset_path\n",
        "        self.sample_fraction = sample_fraction\n",
        "\n",
        "        if load_model:\n",
        "          self.tokenizer = BigBirdTokenizer.from_pretrained('./sentiment_model')\n",
        "          self.model = BigBirdForSequenceClassification.from_pretrained('./sentiment_model')\n",
        "          print('Loaded model and tokenizer')\n",
        "        else:\n",
        "          self.data = pd.read_csv(self.file_path)\n",
        "          self.tokenizer = BigBirdTokenizer.from_pretrained('google/bigbird-roberta-base')\n",
        "          self.model = BigBirdForSequenceClassification.from_pretrained('google/bigbird-roberta-base', num_labels=3)\n",
        "\n",
        "        # Ensure all tensors are contiguous\n",
        "        self.make_tensors_contiguous()\n",
        "\n",
        "    class Preprocessor:\n",
        "        @staticmethod\n",
        "        def preprocess_data(data):\n",
        "            # Map sentiments to labels\n",
        "            label_mapping = {'neutral': 0, 'positive': 1, 'negative': 2}\n",
        "            data['label'] = data['sentiment'].map(label_mapping)\n",
        "            return data[['text', 'label']]\n",
        "\n",
        "        @staticmethod\n",
        "        def clean_text(texts, labels):\n",
        "            cleaned_texts = [text for text in texts if isinstance(text, str) and text.strip() != \"\"]\n",
        "            cleaned_labels = [label for text, label in zip(texts, labels) if isinstance(text, str) and text.strip() != \"\"]\n",
        "            return cleaned_texts, cleaned_labels\n",
        "\n",
        "    class TokenizerWrapper:\n",
        "        def __init__(self, tokenizer):\n",
        "            self.tokenizer = tokenizer\n",
        "\n",
        "        def tokenize(self, texts):\n",
        "            return self.tokenizer(texts, truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "    class ModelTrainer:\n",
        "        def __init__(self, model, tokenizer, train_dataset, test_dataset, data_collator):\n",
        "            self.model = model\n",
        "            self.tokenizer = tokenizer\n",
        "            self.train_dataset = train_dataset\n",
        "            self.test_dataset = test_dataset\n",
        "            self.data_collator = data_collator\n",
        "\n",
        "        def train(self):\n",
        "            # Training arguments\n",
        "            training_args = TrainingArguments(\n",
        "                output_dir='./results',\n",
        "                evaluation_strategy=\"epoch\",\n",
        "                per_device_train_batch_size=8,\n",
        "                per_device_eval_batch_size=8,\n",
        "                num_train_epochs=3,\n",
        "                weight_decay=0.01,\n",
        "                logging_dir='./logs',\n",
        "            )\n",
        "\n",
        "            # Trainer\n",
        "            trainer = Trainer(\n",
        "                model=self.model,\n",
        "                args=training_args,\n",
        "                train_dataset=self.train_dataset,\n",
        "                eval_dataset=self.test_dataset,\n",
        "                tokenizer=self.tokenizer,\n",
        "                data_collator=self.data_collator,\n",
        "                compute_metrics=self.compute_metrics\n",
        "            )\n",
        "\n",
        "            # Train the model\n",
        "            trainer.train()\n",
        "            self.model.save_pretrained('./sentiment_model')\n",
        "            self.tokenizer.save_pretrained('./sentiment_model')\n",
        "            print('Model and tokenizer saved')\n",
        "            return trainer\n",
        "\n",
        "        @staticmethod\n",
        "        def compute_metrics(pred):\n",
        "            labels = pred.label_ids\n",
        "            preds = pred.predictions.argmax(-1)\n",
        "            precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
        "            acc = accuracy_score(labels, preds)\n",
        "            return {\n",
        "                'accuracy': acc,\n",
        "                'precision': precision,\n",
        "                'recall': recall,\n",
        "                'f1': f1,\n",
        "            }\n",
        "\n",
        "    class SentimentPredictor:\n",
        "        def __init__(self, tokenizer, model):\n",
        "            self.tokenizer = tokenizer\n",
        "            self.model = model\n",
        "\n",
        "        def predict_sentiment(self, conversation):\n",
        "            user_text = self.extract_user_text(conversation)\n",
        "            inputs = self.tokenizer(user_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
        "            outputs = self.model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            probs = F.softmax(logits, dim=1)\n",
        "            sentiment = {0: \"neutral\", 1: \"positive\", 2: \"negative\"}\n",
        "            data = {\"sentiment\":[], \"confidence\":[]}\n",
        "            for i, label in sentiment.items():\n",
        "                data[\"sentiment\"].append(label)\n",
        "                data[\"confidence\"].append(probs[0][i].item())\n",
        "            return pd.DataFrame(data)\n",
        "\n",
        "        @staticmethod\n",
        "        def extract_user_text(conversation):\n",
        "            user_texts = [line for line in conversation.split('\\n') if line.startswith(\"User:\")]\n",
        "            return \" \".join([text.replace(\"User:\", \"\").strip() for text in user_texts])\n",
        "\n",
        "    def run_pipeline(self):\n",
        "        # Preprocess and sample data\n",
        "        self.data = self.Preprocessor.preprocess_data(self.data)\n",
        "        train_data_sampled = self.data.sample(frac=self.sample_fraction, random_state=42)\n",
        "\n",
        "        # Split the data\n",
        "        train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "            train_data_sampled['text'].tolist(), train_data_sampled['label'].tolist(), test_size=0.2, random_state=42\n",
        "        )\n",
        "\n",
        "        # Clean the texts\n",
        "        train_texts_clean, train_labels_clean = self.Preprocessor.clean_text(train_texts, train_labels)\n",
        "        test_texts_clean, test_labels_clean = self.Preprocessor.clean_text(test_texts, test_labels)\n",
        "\n",
        "        # Tokenization\n",
        "        tokenizer_wrapper = self.TokenizerWrapper(self.tokenizer)\n",
        "        train_encodings = tokenizer_wrapper.tokenize(train_texts_clean)\n",
        "        test_encodings = tokenizer_wrapper.tokenize(test_texts_clean)\n",
        "\n",
        "        # Create dataset\n",
        "        train_dataset = Dataset.from_dict({\n",
        "            'input_ids': train_encodings['input_ids'],\n",
        "            'attention_mask': train_encodings['attention_mask'],\n",
        "            'labels': train_labels_clean\n",
        "        })\n",
        "\n",
        "        test_dataset = Dataset.from_dict({\n",
        "            'input_ids': test_encodings['input_ids'],\n",
        "            'attention_mask': test_encodings['attention_mask'],\n",
        "            'labels': test_labels_clean\n",
        "        })\n",
        "\n",
        "        # Data collator\n",
        "        data_collator = DataCollatorWithPadding(self.tokenizer)\n",
        "\n",
        "        # Train the model\n",
        "        trainer = self.ModelTrainer(self.model, self.tokenizer, train_dataset, test_dataset, data_collator)\n",
        "        trainer_instance = trainer.train()\n",
        "\n",
        "        # Evaluate the model\n",
        "        trainer_instance.evaluate()\n",
        "\n",
        "    def make_tensors_contiguous(self):\n",
        "        # Make all tensors in the model contiguous\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if not param.is_contiguous():\n",
        "                #print(f\"Making contiguous: {name}\")\n",
        "                param.data = param.data.contiguous()\n",
        "\n",
        "        # Verify if all tensors are now contiguous\n",
        "        #for name, param in self.model.named_parameters():\n",
        "            #print(f\"Layer: {name}, Contiguous: {param.is_contiguous()}\")\n",
        "\n",
        "    def predict(self, conversation):\n",
        "        # Sentiment prediction\n",
        "        sentiment_predictor = self.SentimentPredictor(self.tokenizer, self.model)\n",
        "        return sentiment_predictor.predict_sentiment(conversation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRv9JPKxmEZX"
      },
      "source": [
        "# Contextual Coherence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "# from transformers import BigBirdForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, DataCollatorWithPadding\n",
        "# import torch\n",
        "# from torch.utils.data import Dataset\n",
        "# import pandas as pd\n",
        "# from google.colab import files\n",
        "# import joblib\n",
        "# import os\n",
        "# import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "jjWNIdi0746Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDQVoRudbBWG"
      },
      "outputs": [],
      "source": [
        "# Step 1: Class for defining the custom dataset\n",
        "class DialogueDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length):\n",
        "        self.dataframe = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        context = self.dataframe.iloc[idx, 0]\n",
        "        response = self.dataframe.iloc[idx, 1]\n",
        "        label = self.dataframe.iloc[idx, 2]\n",
        "\n",
        "        combined_text = context + \" \" + self.tokenizer.sep_token + \" \" + response\n",
        "        encoding = self.tokenizer(\n",
        "            combined_text,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        input_ids = encoding[\"input_ids\"].squeeze(0)\n",
        "        attention_mask = encoding[\"attention_mask\"].squeeze(0)\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Step 2: Class for model training\n",
        "class ModelTrainer:\n",
        "    def __init__(self, train_dataset):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('google/bigbird-roberta-base')\n",
        "        self.model = BigBirdForSequenceClassification.from_pretrained('google/bigbird-roberta-base')\n",
        "        self.train_dataset = train_dataset\n",
        "        self.training_args = self._setup_training_args()\n",
        "        for name, param in self.model.named_parameters():\n",
        "          if not param.is_contiguous():\n",
        "            #print(f'Making contiguous:{name}')\n",
        "            param.data = param.data.contiguous()\n",
        "        #for name, param in self.model.named_parameters():\n",
        "            #print(f'Layer:{name}, Contiguous:{param.is_contiguous()}')\n",
        "\n",
        "    def _setup_training_args(self):\n",
        "        # Set up training arguments, limiting to 1 epoch for quick testing\n",
        "        return TrainingArguments(\n",
        "            output_dir='./results',\n",
        "            num_train_epochs=1,  # Quick testing with 1 epoch\n",
        "            per_device_train_batch_size=8,\n",
        "            learning_rate=2e-5,\n",
        "            warmup_steps=500,\n",
        "            weight_decay=0.01,\n",
        "            logging_dir='./logs',\n",
        "            logging_steps=50,\n",
        "            save_total_limit=2,\n",
        "            save_steps=200,\n",
        "            evaluation_strategy=\"no\",\n",
        "        )\n",
        "\n",
        "    def fine_tune_model(self):\n",
        "        trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=self.training_args,\n",
        "            train_dataset=self.train_dataset\n",
        "        )\n",
        "        trainer.train()\n",
        "        return self.model\n",
        "\n",
        "    def save_model(self, save_path):\n",
        "        self.model.save_pretrained(save_path)\n",
        "        self.tokenizer.save_pretrained(save_path)\n",
        "        print(f\"Model saved to {save_path}\")\n",
        "\n",
        "# Step 3: Class for coherence evaluation\n",
        "class CoherenceEvaluator:\n",
        "    def __init__(self, model_path):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        self.model = BigBirdForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "    def tokenize_input(self, context, response):\n",
        "        return self.tokenizer(context, response, return_tensors='pt', max_length=1024, truncation=True, padding='max_length')\n",
        "\n",
        "    def compute_logits(self, inputs):\n",
        "        outputs = self.model(**inputs)\n",
        "        return outputs.logits\n",
        "\n",
        "    def apply_softmax(self, logits):\n",
        "        probabilities = F.softmax(logits, dim=1)\n",
        "        return probabilities[0][1].item()\n",
        "\n",
        "# Step 4: Main pipeline class to encapsulate the entire process\n",
        "class CoherencePipeline:\n",
        "    def __init__(self, dataset_path, model_save_path, load_model=False):\n",
        "        self.file_path = dataset_path\n",
        "        self.model_save_path = model_save_path\n",
        "        self.load_model = load_model\n",
        "        self.model_trainer = None\n",
        "        self.coherence_evaluator = None\n",
        "\n",
        "    def prepare_dataset(self):\n",
        "        df = pd.read_csv(self.file_path)\n",
        "        tokenizer = AutoTokenizer.from_pretrained('google/bigbird-roberta-base')\n",
        "        train_dataset = DialogueDataset(df, tokenizer, max_length=256)\n",
        "        return train_dataset\n",
        "\n",
        "    def train_and_save_model(self, train_dataset):\n",
        "        self.model_trainer = ModelTrainer(train_dataset)\n",
        "        trained_model = self.model_trainer.fine_tune_model()\n",
        "        self.model_trainer.save_model(self.model_save_path)\n",
        "        return trained_model\n",
        "\n",
        "    def evaluate_coherence(self):\n",
        "        #file_name = list(self.file_path.keys())[0]\n",
        "        with open(self.file_path, 'r') as file:\n",
        "            dialogue = file.readlines()\n",
        "\n",
        "        self.coherence_evaluator = CoherenceEvaluator(self.model_save_path)\n",
        "        pairs = [(dialogue[i].strip(), dialogue[i + 1].strip()) for i in range(len(dialogue) - 1)]\n",
        "\n",
        "        scores = []\n",
        "        for context, response in pairs:\n",
        "            inputs = self.coherence_evaluator.tokenize_input(context, response)\n",
        "            logits = self.coherence_evaluator.compute_logits(inputs)\n",
        "            score = self.coherence_evaluator.apply_softmax(logits)\n",
        "            scores.append(score)\n",
        "\n",
        "        # Create DataFrame to store results\n",
        "        df_results = pd.DataFrame({\n",
        "            'Pair Number': [f'Pair {i+1}' for i in range(len(pairs))],\n",
        "            'Context': [pair[0] for pair in pairs],\n",
        "            'Response': [pair[1] for pair in pairs],\n",
        "            'Coherence Score': scores\n",
        "        })\n",
        "\n",
        "        # Calculate overall coherence score\n",
        "        overall_score = sum(scores) / len(scores)\n",
        "        df_results.loc['Overall'] = ['', '', 'Overall Coherence Score', overall_score]\n",
        "\n",
        "        return df_results\n",
        "\n",
        "    def run_pipeline(self):\n",
        "        if self.load_model:\n",
        "            # Check if fine-tuned model exists\n",
        "            if self.model_save_path.startswith('google/'):\n",
        "              print(f'Using pretrained model from Hugging Face:{self.model_save_path}')\n",
        "            else:\n",
        "                if not os.path.exists(self.model_save_path):\n",
        "                    raise FileNotFoundError(f\"No fine-tuned model found at {self.model_save_path}. Please train the model first.\")\n",
        "                print(f\"Using existing model from {self.model_save_path}\")\n",
        "        else:\n",
        "            # Train model if flag is set to True\n",
        "            train_dataset = self.prepare_dataset()\n",
        "            self.train_and_save_model(train_dataset)\n",
        "\n",
        "        # Proceed to evaluate test data\n",
        "        df_results = self.evaluate_coherence()\n",
        "        print(df_results)\n",
        "        return df_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xDTQo_nRNez"
      },
      "source": [
        "# Final Calculation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "uqaWXePsNC6W",
        "outputId": "6b2cf5e3-ee4f-48ef-ba69-e45fc3bbab3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Example usage for both variations:\\n\\n# Variation 1: Example DataFrame with emotion, level, and confidence\\ndata_emotion = {\\n    \\'audio_file\\': [\\'audio1.mp3\\', \\'audio1.mp3\\', \\'audio1.mp3\\', \\'audio1.mp3\\'],\\n    \\'emotion\\': [\\'Happiness\\', \\'Anger\\', \\'Neutral\\', \\'Sadness\\'],\\n    \\'level\\': [\\'High\\', \\'Medium\\', \\'Unspecified\\', \\'Low\\'],\\n    \\'confidence\\': [0.6, 0.2, 0.1, 0.1]\\n}\\ndf_emotion = pd.DataFrame(data_emotion)\\n\\n# Variation 2: Example DataFrame with Sentiment, Confidence, and Score\\ndata_sentiment = {\\n    \\'Sentiment\\': [\\'neutral\\', \\'positive\\', \\'negative\\'],\\n    \\'Confidence\\': [0.868819, 0.049960, 0.081221]\\n    #\\'Score\\': [0, 1, -1]\\n}\\ndf_sentiment = pd.DataFrame(data_sentiment)\\n\\n# Calculate the final score for both variations\\nfinal_score_emotion = calculate_final_score(df_emotion)\\nfinal_score_sentiment = calculate_final_score(df_sentiment)\\n\\nprint(f\"Final score (Emotion DataFrame): {final_score_emotion:.2f}\")\\nprint(f\"Final score (Sentiment DataFrame): {final_score_sentiment:.2f}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# import pandas as pd\n",
        "# import math\n",
        "\n",
        "# Function to map emotion and level to a score\n",
        "def map_emotion_to_score(emotion, level):\n",
        "    emotion_scores = {\n",
        "        'Happiness': {'Low': 1, 'Medium': 2, 'High': 3, 'Unspecified': 2},\n",
        "        'Neutral': {'Low': 0, 'Medium': 0, 'High': 0, 'Unspecified': 0},\n",
        "        'Anger': {'Low': -1, 'Medium': -2, 'High': -3, 'Unspecified': -2},\n",
        "        'Disgust': {'Low': -1, 'Medium': -2, 'High': -3, 'Unspecified': -2},\n",
        "        'Fear': {'Low': -1, 'Medium': -2, 'High': -3, 'Unspecified': -2},\n",
        "        'Sadness': {'Low': -1, 'Medium': -2, 'High': -3, 'Unspecified': -2}\n",
        "    }\n",
        "    return emotion_scores.get(emotion, {'Medium': 0}).get(level, 0)\n",
        "\n",
        "# Function to map sentiment to score\n",
        "def map_sentiment_to_score(sentiment):\n",
        "    sentiment_scores = {'Neutral':0, 'Negative':-1, 'Positive':1}\n",
        "    return sentiment_scores.get(sentiment, 0)\n",
        "\n",
        "# Function to apply sigmoid transformation and scale\n",
        "def sigmoid_transform(x):\n",
        "    x_sigmoid = 1 / (1 + math.exp(-x))\n",
        "    x_scaled = x_sigmoid * 10\n",
        "    return x_scaled\n",
        "\n",
        "# Unified function to calculate the final score from any input format\n",
        "def calculate_sentiment_score(df):\n",
        "    if 'emotion' in df.columns and 'level' in df.columns:\n",
        "        # Process DataFrame with emotions and levels\n",
        "        df['score'] = df.apply(lambda row: map_emotion_to_score(row['emotion'], row['level']), axis=1)\n",
        "        df['weighted_score'] = df['score'] * df['confidence']\n",
        "    elif 'sentiment' in df.columns:\n",
        "        # Process DataFrame with Sentiment, Confidence, and Score\n",
        "        df['score'] = df.apply(lambda row: map_sentiment_to_score(row['sentiment']), axis = 1)\n",
        "        df['weighted_score'] = df['score'] * df['confidence']\n",
        "    else:\n",
        "        raise ValueError(\"DataFrame format not recognized.\")\n",
        "\n",
        "    # Calculate weighted sum of scores\n",
        "    weighted_sum = df['weighted_score'].sum()\n",
        "\n",
        "    # Calculate total confidence\n",
        "    total_confidence = df['confidence'].sum()\n",
        "\n",
        "    # Compute the final raw score\n",
        "    sentiment_score_raw = weighted_sum / total_confidence if total_confidence != 0 else 0\n",
        "\n",
        "    # Apply sigmoid transformation to the final score\n",
        "    sentiment_score = sigmoid_transform(sentiment_score_raw)\n",
        "\n",
        "    return sentiment_score, total_confidence\n",
        "\n",
        "def weighted_score(audio_score, audio_confidence, text_score, text_confidence):\n",
        "    return (audio_score * audio_confidence + text_score * text_confidence) / (audio_confidence + text_confidence)\n",
        "\n",
        "'''\n",
        "# Example usage for both variations:\n",
        "\n",
        "# Variation 1: Example DataFrame with emotion, level, and confidence\n",
        "data_emotion = {\n",
        "    'audio_file': ['audio1.mp3', 'audio1.mp3', 'audio1.mp3', 'audio1.mp3'],\n",
        "    'emotion': ['Happiness', 'Anger', 'Neutral', 'Sadness'],\n",
        "    'level': ['High', 'Medium', 'Unspecified', 'Low'],\n",
        "    'confidence': [0.6, 0.2, 0.1, 0.1]\n",
        "}\n",
        "df_emotion = pd.DataFrame(data_emotion)\n",
        "\n",
        "# Variation 2: Example DataFrame with Sentiment, Confidence, and Score\n",
        "data_sentiment = {\n",
        "    'Sentiment': ['neutral', 'positive', 'negative'],\n",
        "    'Confidence': [0.868819, 0.049960, 0.081221]\n",
        "    #'Score': [0, 1, -1]\n",
        "}\n",
        "df_sentiment = pd.DataFrame(data_sentiment)\n",
        "\n",
        "# Calculate the final score for both variations\n",
        "final_score_emotion = calculate_final_score(df_emotion)\n",
        "final_score_sentiment = calculate_final_score(df_sentiment)\n",
        "\n",
        "print(f\"Final score (Emotion DataFrame): {final_score_emotion:.2f}\")\n",
        "print(f\"Final score (Sentiment DataFrame): {final_score_sentiment:.2f}\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg-9RH3wweMM"
      },
      "source": [
        "# Main Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Md1c21Ju-0bi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d902a05-ff46-4a6c-ef5b-b9e811c034c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 7442 labels from the files.\n",
            "Dataset size before splitting: (7442, 2)\n",
            "Model, scaler, label encoder, and feature names loaded successfully.\n",
            "audio1.mp3 downloaded\n",
            "    audio_file    emotion        level  confidence\n",
            "0   audio1.mp3      Anger  Unspecified    0.832003\n",
            "1   audio1.mp3    Disgust  Unspecified    0.084818\n",
            "2   audio1.mp3       Fear  Unspecified    0.037596\n",
            "3   audio1.mp3  Happiness  Unspecified    0.013726\n",
            "4   audio1.mp3    Neutral  Unspecified    0.010456\n",
            "5   audio1.mp3    Sadness  Unspecified    0.005088\n",
            "6   audio1.mp3      Anger       Medium    0.003968\n",
            "7   audio1.mp3    Sadness          Low    0.001975\n",
            "8   audio1.mp3       Fear         High    0.001580\n",
            "9   audio1.mp3      Anger         High    0.001542\n",
            "10  audio1.mp3  Happiness         High    0.001529\n",
            "11  audio1.mp3    Disgust         High    0.001103\n",
            "12  audio1.mp3      Anger          Low    0.000811\n",
            "13  audio1.mp3       Fear          Low    0.000716\n",
            "14  audio1.mp3  Happiness       Medium    0.000674\n",
            "15  audio1.mp3    Disgust       Medium    0.000562\n",
            "16  audio1.mp3  Happiness          Low    0.000438\n",
            "17  audio1.mp3       Fear       Medium    0.000422\n",
            "18  audio1.mp3    Sadness         High    0.000375\n",
            "19  audio1.mp3    Disgust          Low    0.000341\n",
            "20  audio1.mp3    Sadness       Medium    0.000277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Attention type 'block_sparse' is not possible if sequence_length: 2 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model and tokenizer\n",
            "  sentiment  confidence\n",
            "0   neutral    0.414615\n",
            "1  positive    0.296426\n",
            "2  negative    0.288958\n",
            "Final score (Emotion DataFrame mingyao): 1.29\n",
            "Final score (Sentiment DataFrame bhavik): 5.00\n",
            "Weighted score for user satisfaction: 3.14\n",
            "Using existing model from ./coherence_model\n",
            "        Pair Number                                            Context  \\\n",
            "0            Pair 1  [\"AI: Hi, my name is Lila. I'm Octivo's AI age...   \n",
            "1            Pair 2  \"Caller: Hey, nice to meet you. My name is Mic...   \n",
            "2            Pair 3  \"AI: Thank you for introducing yourself Michae...   \n",
            "3            Pair 4  \"Caller: Yeah, sure. I'm 27 but I feel like I ...   \n",
            "4            Pair 5  \"AI: I completely understand your hesitation a...   \n",
            "5            Pair 6  \"Caller: Ok, that's fair enough. So I'm earnin...   \n",
            "6            Pair 7  \"AI: Thank you for sharing your income range t...   \n",
            "7            Pair 8  \"Caller: I will retire at around 65 and I woul...   \n",
            "Overall                                                                  \n",
            "\n",
            "                                                  Response  Coherence Score  \n",
            "0        \"Caller: Hey, nice to meet you. My name is Mic...         0.590054  \n",
            "1        \"AI: Thank you for introducing yourself Michae...         0.766010  \n",
            "2        \"Caller: Yeah, sure. I'm 27 but I feel like I ...         0.754133  \n",
            "3        \"AI: I completely understand your hesitation a...         0.769230  \n",
            "4        \"Caller: Ok, that's fair enough. So I'm earnin...         0.767711  \n",
            "5        \"AI: Thank you for sharing your income range t...         0.761523  \n",
            "6        \"Caller: I will retire at around 65 and I woul...         0.762877  \n",
            "7        \"AI: It was an absolute pleasure assisting you...         0.767307  \n",
            "Overall                            Overall Coherence Score         0.742356  \n",
            "Final score: 2.33\n"
          ]
        }
      ],
      "source": [
        "# Main function to run the pipeline\n",
        "def main():\n",
        "\n",
        "  # Define Google Drive file IDs\n",
        "  audio_file_ids = {\n",
        "      'audio1.mp3': '108kPpEQeA_6RkQXmmLWDJXQzdiISlm0r'\n",
        "  }\n",
        "\n",
        "  # Create and run the AudioEmotionDetectionPipeline\n",
        "  audio_pipeline = AudioEmotionDetectionPipeline(audio_file_ids)\n",
        "  audio_results_df = audio_pipeline.run()\n",
        "\n",
        "  # Output the audio results\n",
        "  print(audio_results_df)\n",
        "\n",
        "  # Load sentiment analysis model to predict sentiment and confidence scores\n",
        "  text_pipeline = TextSentimentAnalysisPipeline(load_model = True) # change to TextSentimentAnalysisPipeline('/content/train.csv') and text_pipeline.run_pipeline() if training\n",
        "  textresults_df = text_pipeline.predict('/content/dialogue1.txt') # comment out if using training model\n",
        "  print(textresults_df)\n",
        "\n",
        "  final_score_emotion, emotion_confidence = calculate_sentiment_score(audio_results_df)\n",
        "  final_score_sentiment, sentiment_confidence = calculate_sentiment_score(textresults_df)\n",
        "\n",
        "  print(f\"Final score (Emotion DataFrame mingyao): {final_score_emotion:.2f}\")\n",
        "  print(f\"Final score (Sentiment DataFrame bhavik): {final_score_sentiment:.2f}\")\n",
        "\n",
        "  user_satisfaction = weighted_score(final_score_emotion, emotion_confidence, final_score_sentiment, sentiment_confidence)\n",
        "  print(f\"Weighted score for user satisfaction: {user_satisfaction:.2f}\")\n",
        "\n",
        "  coherence_pipeline = CoherencePipeline(\n",
        "    dataset_path = '/content/dialogue1.txt', # Change to '/content/dialogues_dataset.csv' if you want to train\n",
        "    model_save_path='./coherence_model', load_model=True)  # Set to False if you want to train\n",
        "  coherence_result = coherence_pipeline.run_pipeline()\n",
        "  coherence_score = coherence_result.loc['Overall', 'Coherence Score']\n",
        "\n",
        "  final_score = user_satisfaction*coherence_score\n",
        "  print(f\"Final score: {final_score:.2f}\")\n",
        "\n",
        "  #score = calculate_final_score(emotions, levels, confidences)\n",
        "  #print(f\"Final score: {score:.2f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contextual Coherence (ignore - for record keeping)"
      ],
      "metadata": {
        "id": "xEonGw4qid-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from transformers import BigBirdForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import joblib\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "from google.colab import drive\n",
        "import gc\n",
        "\n",
        "# Step 0: Safely handle mounting Google Drive\n",
        "if not os.path.ismount('/content/drive'):\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "    print(\"Drive mounted successfully.\")\n",
        "else:\n",
        "    print(\"Google Drive is already mounted.\")\n",
        "\n",
        "# Clear cache and collect garbage to free memory\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Step 1: Class for handling file operations and dataset management\n",
        "class DatasetHandler:\n",
        "    def __init__(self, save_directory):\n",
        "        self.save_directory = save_directory\n",
        "        self.train_dataset_file = os.path.join(self.save_directory, 'saved_train_dataset.pkl')\n",
        "        self.dataframe = None\n",
        "\n",
        "    def create_save_directory(self):\n",
        "        if not os.path.exists(self.save_directory):\n",
        "            os.makedirs(self.save_directory)\n",
        "            print(f\"Created directory: {self.save_directory}\")\n",
        "\n",
        "    def load_or_upload_dataset(self):\n",
        "        if not os.path.exists(self.train_dataset_file):\n",
        "            print(\"Training dataset file not found in Google Drive. Please upload the dataset.\")\n",
        "            uploaded = files.upload()\n",
        "            file_name = list(uploaded.keys())[0]\n",
        "            self.dataframe = pd.read_csv(file_name)\n",
        "            joblib.dump(self.dataframe, self.train_dataset_file)\n",
        "            print(f\"Dataset saved to {self.train_dataset_file} in Google Drive.\")\n",
        "        else:\n",
        "            # Load the dataset from Google Drive if it already exists\n",
        "            self.dataframe = joblib.load(self.train_dataset_file)\n",
        "            print(f\"Dataset loaded from {self.train_dataset_file} in Google Drive.\")\n",
        "        return self.dataframe\n",
        "\n",
        "# Step 2: Class for defining the custom dataset\n",
        "class DialogueDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length):\n",
        "        self.dataframe = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        context = self.dataframe.iloc[idx, 0]\n",
        "        response = self.dataframe.iloc[idx, 1]\n",
        "        label = self.dataframe.iloc[idx, 2]\n",
        "\n",
        "        combined_text = context + \" \" + self.tokenizer.sep_token + \" \" + response\n",
        "        encoding = self.tokenizer(\n",
        "            combined_text,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        input_ids = encoding[\"input_ids\"].squeeze(0)\n",
        "        attention_mask = encoding[\"attention_mask\"].squeeze(0)\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Custom Trainer class to handle non-contiguous tensor issue\n",
        "class CustomTrainer(Trainer):\n",
        "    def save_model(self, output_dir=None, _internal_call=False):\n",
        "        # Make all tensors contiguous before saving\n",
        "        for param in self.model.parameters():\n",
        "            param.data = param.data.contiguous()\n",
        "        super().save_model(output_dir, _internal_call=_internal_call)\n",
        "\n",
        "# Step 3: Class for model training\n",
        "class ModelTrainer:\n",
        "    def __init__(self, model_name, train_dataset):\n",
        "        self.model_name = model_name\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "        self.model = BigBirdForSequenceClassification.from_pretrained(self.model_name)\n",
        "        self.train_dataset = train_dataset\n",
        "        self.training_args = self._setup_training_args()\n",
        "\n",
        "    def _setup_training_args(self):\n",
        "        # Set up training arguments, limiting to 1 epoch for quick testing\n",
        "        return TrainingArguments(\n",
        "            output_dir='./results',\n",
        "            num_train_epochs=1,  # Quick testing with 1 epoch\n",
        "            per_device_train_batch_size=2,\n",
        "            learning_rate=2e-5,\n",
        "            warmup_steps=500,\n",
        "            weight_decay=0.01,\n",
        "            logging_dir='./logs',\n",
        "            logging_steps=50,\n",
        "            save_total_limit=2,\n",
        "            save_steps=200,\n",
        "            evaluation_strategy=\"no\",\n",
        "        )\n",
        "\n",
        "    def fine_tune_model(self):\n",
        "        trainer = CustomTrainer(\n",
        "            model=self.model,\n",
        "            args=self.training_args,\n",
        "            train_dataset=self.train_dataset\n",
        "        )\n",
        "        trainer.train()\n",
        "        return self.model\n",
        "\n",
        "    def save_model(self, save_path):\n",
        "        # Ensure all tensors are contiguous before saving\n",
        "        for param in self.model.parameters():\n",
        "            param.data = param.data.contiguous()\n",
        "        self.model.save_pretrained(save_path)\n",
        "        self.tokenizer.save_pretrained(save_path)\n",
        "        print(f\"Model saved to {save_path}\")\n",
        "\n",
        "# Step 4: Class for coherence evaluation with memory management\n",
        "class CoherenceEvaluator:\n",
        "    def __init__(self, model_path):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        self.model = BigBirdForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "        # Move model to CPU to avoid GPU memory issues\n",
        "        device = torch.device('cpu')\n",
        "        self.model = self.model.to(device)\n",
        "\n",
        "    def tokenize_input(self, context, response):\n",
        "        return self.tokenizer(context, response, return_tensors='pt', max_length=1024, truncation=True, padding='max_length')\n",
        "\n",
        "    def compute_logits(self, inputs):\n",
        "        # Move inputs to the same device as the model\n",
        "        inputs = {key: val.to(self.model.device) for key, val in inputs.items()}\n",
        "        outputs = self.model(**inputs)\n",
        "        return outputs.logits\n",
        "\n",
        "    def apply_softmax(self, logits):\n",
        "        probabilities = F.softmax(logits, dim=1)\n",
        "        return probabilities[0][1].item()\n",
        "\n",
        "# Step 5: Main pipeline class to encapsulate the entire process\n",
        "class CoherencePipeline:\n",
        "    def __init__(self, dataset_directory, model_name, model_save_path, train_model=True):\n",
        "        self.dataset_directory = dataset_directory\n",
        "        self.model_name = model_name\n",
        "        self.model_save_path = model_save_path\n",
        "        self.train_model = train_model\n",
        "        self.dataset_handler = DatasetHandler(dataset_directory)\n",
        "        self.model_trainer = None\n",
        "        self.coherence_evaluator = None\n",
        "\n",
        "    def prepare_dataset(self):\n",
        "        self.dataset_handler.create_save_directory()\n",
        "        df = self.dataset_handler.load_or_upload_dataset()\n",
        "        tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "        train_dataset = DialogueDataset(df, tokenizer, max_length=256)\n",
        "        return train_dataset\n",
        "\n",
        "    def train_and_save_model(self, train_dataset):\n",
        "        self.model_trainer = ModelTrainer(self.model_name, train_dataset)\n",
        "        trained_model = self.model_trainer.fine_tune_model()\n",
        "        self.model_trainer.save_model(self.model_save_path)\n",
        "        return trained_model\n",
        "\n",
        "    def evaluate_coherence(self, dialogue_file_path):\n",
        "        print(\"Please upload the test file for evaluation:\")\n",
        "        uploaded = files.upload()\n",
        "        file_name = list(uploaded.keys())[0]\n",
        "        with open(file_name, 'r') as file:\n",
        "            dialogue = file.readlines()\n",
        "\n",
        "        self.coherence_evaluator = CoherenceEvaluator(self.model_save_path)\n",
        "        pairs = [(dialogue[i].strip(), dialogue[i + 1].strip()) for i in range(len(dialogue) - 1)]\n",
        "\n",
        "        scores = []\n",
        "        for context, response in pairs:\n",
        "            inputs = self.coherence_evaluator.tokenize_input(context, response)\n",
        "            logits = self.coherence_evaluator.compute_logits(inputs)\n",
        "            score = self.coherence_evaluator.apply_softmax(logits)\n",
        "            scores.append(score)\n",
        "\n",
        "        # Create DataFrame to store results\n",
        "        df_results = pd.DataFrame({\n",
        "            'Pair Number': [f'Pair {i+1}' for i in range(len(pairs))],\n",
        "            'Context': [pair[0] for pair in pairs],\n",
        "            'Response': [pair[1] for pair in pairs],\n",
        "            'Coherence Score': scores\n",
        "        })\n",
        "\n",
        "        # Calculate overall coherence score\n",
        "        overall_score = sum(scores) / len(scores)\n",
        "        df_results.loc['Overall'] = ['', '', 'Overall Coherence Score', overall_score]\n",
        "\n",
        "        return df_results\n",
        "\n",
        "    def run_pipeline(self):\n",
        "        if self.train_model:\n",
        "            # Train model if flag is set to True\n",
        "            train_dataset = self.prepare_dataset()\n",
        "            self.train_and_save_model(train_dataset)\n",
        "        else:\n",
        "            # Check if using a pretrained model from Hugging Face\n",
        "            if self.model_save_path.startswith(\"google/\"):\n",
        "                print(f\"Using pretrained model from Hugging Face: {self.model_save_path}\")\n",
        "            else:\n",
        "                # Check if fine-tuned model exists locally\n",
        "                if not os.path.exists(self.model_save_path):\n",
        "                    raise FileNotFoundError(f\"No fine-tuned model found at {self.model_save_path}. Please train the model first.\")\n",
        "                print(f\"Using existing model from {self.model_save_path}\")\n",
        "\n",
        "        # Proceed to evaluate test data and get DataFrame\n",
        "        df_results = self.evaluate_coherence('your_dialogue_test_file.txt')\n",
        "        print(df_results)\n",
        "        return df_results\n",
        "\n",
        "# Step 6: Run the pipeline\n",
        "pipeline = CoherencePipeline(\n",
        "    dataset_directory='/content/drive/MyDrive/Coherence_Model',\n",
        "    model_name=\"google/bigbird-roberta-base\",\n",
        "    model_save_path=\"google/bigbird-roberta-base\",  # Pretrained model path\n",
        "    train_model=False  # Set to True if you want to train, False to use existing model\n",
        ")\n",
        "\n",
        "# Run the pipeline\n",
        "df_results = pipeline.run_pipeline()\n"
      ],
      "metadata": {
        "id": "cK_anv60VwXU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860,
          "referenced_widgets": [
            "a5def294af844d56ae51b930ba53acd1",
            "e5633e8810314dafa39c61322ff37567",
            "feb1722b6d964e30aef55fbf2b6d2616",
            "2eb96d1c48224793a4fab7336791cb5e",
            "797266bfa33c44f8b9d5d4d692f8903d",
            "9696c300ca0b4cd6b61679030640f951",
            "847d351df03341939c8839a5b568c09b",
            "9e1c3bd6969a48b69c9693e27c59b69d",
            "e38a4b104ed345e8a8c76650913ecb37",
            "baec247e01244ba4839c8264f3851cf4",
            "8ab2ad5e6d314e4da25c493f8531caa3",
            "1df05f41434940d49dd056909942df69",
            "d12173dea96c464092d3781515fcfe37",
            "895346f9506c4966a47c74b1e8f36b29",
            "aa9fac80f3df4de28dd598e24f843f16",
            "c216aa94cfc14031ab5f9de21890af85",
            "666ec8aa74aa469cb067c1d85343ea41",
            "2313cca4e4fc4cd3bb9aad6017733f9b",
            "9f4475d0c74a460bbc230e96c4585d81",
            "d40592221b434e4baba90beabe03ab97",
            "f879e78d34aa46199002661a9c3d618c",
            "0fd25955e05942f196672bda6d268d13",
            "01d17e6bc70e43fa987f662334184fc8",
            "e2bbc891a4724f0da898c123d7a8d50e",
            "d80994884b8648f3a208b5660ced2c6d",
            "b91bb80f70df462f8a6eaffdd9ad11e2",
            "c72325519618431cb1b2c5e08a3bb28c",
            "52e9b0555f3d4d0d9b3d0d97eeaae118",
            "5c74628ac0964ee6b57a9621cc3803bf",
            "30b560c72709412fb2e523017522eb88",
            "8c0cfd75bf5d4be7a797474ab40f441e",
            "3ef1563cae92437681cbbae7b4b33c28",
            "c86805c8fd7d43c587b547b9726fd9a0",
            "704db5ebc24f44198d77cc09b9669e23",
            "e1f4fc89d0fd41f9bf8573fa84059fc2",
            "4f367185c50c405fb6f8561a50549b55",
            "847d33ebd71a454d8938bc0457c74fb3",
            "94b7c159a3374c72b0e0e24bbb9a8345",
            "a79a28ce690d410b8fccaffd9cdc3e96",
            "253d76e2b6954744abcfcf25a8c2d18e",
            "48c972e27167450588b34ad82854dd9f",
            "471b4733897447aeb1b7a52afc55971f",
            "7d026443bd4e4a01acc0cf57f34479cf",
            "a8b1038686b341fdaa6db9a2461df170",
            "3ec5103d14474809b3dabf462d605fc2",
            "9385ae891a114cbebcad517e20312759",
            "8f7c69f798294c66b8492967b2c62041",
            "9bbc68861f074e4b9337fb6b48ca76d1",
            "64145a4aa0754c52aae89e7163f6f0e7",
            "d3f8ae7c6c1742f48d9f4b1c1ff5f394",
            "cf8f947551c64073945c3bc906c95ab2",
            "067fc824211848a29f85b0ef7a283887",
            "b248350962f0446aab49ad51f3d99dd3",
            "5c05e45064fb4aca9d8aee901c117476",
            "e0a79bb68700458b8039605af12c5197"
          ]
        },
        "outputId": "05ea46a0-8278-4867-d2fe-d892a7d8c5fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Drive mounted successfully.\n",
            "Using pretrained model from Hugging Face: google/bigbird-roberta-base\n",
            "Please upload the test file for evaluation:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-615aeb2e-484d-45bb-b4da-a8e02ca3dc4a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-615aeb2e-484d-45bb-b4da-a8e02ca3dc4a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dialogue1.txt to dialogue1.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5def294af844d56ae51b930ba53acd1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1df05f41434940d49dd056909942df69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/846k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01d17e6bc70e43fa987f662334184fc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/775 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "704db5ebc24f44198d77cc09b9669e23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ec5103d14474809b3dabf462d605fc2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Pair Number                                            Context  \\\n",
            "0            Pair 1  [\"AI: Hi, my name is Lila. I'm Octivo's AI age...   \n",
            "1            Pair 2  \"Caller: Hey, nice to meet you. My name is Mic...   \n",
            "2            Pair 3  \"AI: Thank you for introducing yourself Michae...   \n",
            "3            Pair 4  \"Caller: Yeah, sure. I'm 27 but I feel like I ...   \n",
            "4            Pair 5  \"AI: I completely understand your hesitation a...   \n",
            "5            Pair 6  \"Caller: Ok, that's fair enough. So I'm earnin...   \n",
            "6            Pair 7  \"AI: Thank you for sharing your income range t...   \n",
            "7            Pair 8  \"Caller: I will retire at around 65 and I woul...   \n",
            "Overall                                                                  \n",
            "\n",
            "                                                  Response  Coherence Score  \n",
            "0        \"Caller: Hey, nice to meet you. My name is Mic...         0.566975  \n",
            "1        \"AI: Thank you for introducing yourself Michae...         0.552891  \n",
            "2        \"Caller: Yeah, sure. I'm 27 but I feel like I ...         0.556639  \n",
            "3        \"AI: I completely understand your hesitation a...         0.551340  \n",
            "4        \"Caller: Ok, that's fair enough. So I'm earnin...         0.545934  \n",
            "5        \"AI: Thank you for sharing your income range t...         0.556528  \n",
            "6        \"Caller: I will retire at around 65 and I woul...         0.557095  \n",
            "7        \"AI: It was an absolute pleasure assisting you...         0.550583  \n",
            "Overall                            Overall Coherence Score         0.554748  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fofOcT8RL_K"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xEonGw4qid-0"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a5def294af844d56ae51b930ba53acd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5633e8810314dafa39c61322ff37567",
              "IPY_MODEL_feb1722b6d964e30aef55fbf2b6d2616",
              "IPY_MODEL_2eb96d1c48224793a4fab7336791cb5e"
            ],
            "layout": "IPY_MODEL_797266bfa33c44f8b9d5d4d692f8903d"
          }
        },
        "e5633e8810314dafa39c61322ff37567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9696c300ca0b4cd6b61679030640f951",
            "placeholder": "​",
            "style": "IPY_MODEL_847d351df03341939c8839a5b568c09b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "feb1722b6d964e30aef55fbf2b6d2616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e1c3bd6969a48b69c9693e27c59b69d",
            "max": 1017,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e38a4b104ed345e8a8c76650913ecb37",
            "value": 1017
          }
        },
        "2eb96d1c48224793a4fab7336791cb5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baec247e01244ba4839c8264f3851cf4",
            "placeholder": "​",
            "style": "IPY_MODEL_8ab2ad5e6d314e4da25c493f8531caa3",
            "value": " 1.02k/1.02k [00:00&lt;00:00, 27.7kB/s]"
          }
        },
        "797266bfa33c44f8b9d5d4d692f8903d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9696c300ca0b4cd6b61679030640f951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "847d351df03341939c8839a5b568c09b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e1c3bd6969a48b69c9693e27c59b69d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e38a4b104ed345e8a8c76650913ecb37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "baec247e01244ba4839c8264f3851cf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ab2ad5e6d314e4da25c493f8531caa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1df05f41434940d49dd056909942df69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d12173dea96c464092d3781515fcfe37",
              "IPY_MODEL_895346f9506c4966a47c74b1e8f36b29",
              "IPY_MODEL_aa9fac80f3df4de28dd598e24f843f16"
            ],
            "layout": "IPY_MODEL_c216aa94cfc14031ab5f9de21890af85"
          }
        },
        "d12173dea96c464092d3781515fcfe37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_666ec8aa74aa469cb067c1d85343ea41",
            "placeholder": "​",
            "style": "IPY_MODEL_2313cca4e4fc4cd3bb9aad6017733f9b",
            "value": "config.json: 100%"
          }
        },
        "895346f9506c4966a47c74b1e8f36b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f4475d0c74a460bbc230e96c4585d81",
            "max": 760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d40592221b434e4baba90beabe03ab97",
            "value": 760
          }
        },
        "aa9fac80f3df4de28dd598e24f843f16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f879e78d34aa46199002661a9c3d618c",
            "placeholder": "​",
            "style": "IPY_MODEL_0fd25955e05942f196672bda6d268d13",
            "value": " 760/760 [00:00&lt;00:00, 14.8kB/s]"
          }
        },
        "c216aa94cfc14031ab5f9de21890af85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "666ec8aa74aa469cb067c1d85343ea41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2313cca4e4fc4cd3bb9aad6017733f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f4475d0c74a460bbc230e96c4585d81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d40592221b434e4baba90beabe03ab97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f879e78d34aa46199002661a9c3d618c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fd25955e05942f196672bda6d268d13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01d17e6bc70e43fa987f662334184fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2bbc891a4724f0da898c123d7a8d50e",
              "IPY_MODEL_d80994884b8648f3a208b5660ced2c6d",
              "IPY_MODEL_b91bb80f70df462f8a6eaffdd9ad11e2"
            ],
            "layout": "IPY_MODEL_c72325519618431cb1b2c5e08a3bb28c"
          }
        },
        "e2bbc891a4724f0da898c123d7a8d50e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52e9b0555f3d4d0d9b3d0d97eeaae118",
            "placeholder": "​",
            "style": "IPY_MODEL_5c74628ac0964ee6b57a9621cc3803bf",
            "value": "spiece.model: 100%"
          }
        },
        "d80994884b8648f3a208b5660ced2c6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30b560c72709412fb2e523017522eb88",
            "max": 845731,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c0cfd75bf5d4be7a797474ab40f441e",
            "value": 845731
          }
        },
        "b91bb80f70df462f8a6eaffdd9ad11e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ef1563cae92437681cbbae7b4b33c28",
            "placeholder": "​",
            "style": "IPY_MODEL_c86805c8fd7d43c587b547b9726fd9a0",
            "value": " 846k/846k [00:02&lt;00:00, 325kB/s]"
          }
        },
        "c72325519618431cb1b2c5e08a3bb28c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52e9b0555f3d4d0d9b3d0d97eeaae118": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c74628ac0964ee6b57a9621cc3803bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30b560c72709412fb2e523017522eb88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c0cfd75bf5d4be7a797474ab40f441e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ef1563cae92437681cbbae7b4b33c28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c86805c8fd7d43c587b547b9726fd9a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "704db5ebc24f44198d77cc09b9669e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1f4fc89d0fd41f9bf8573fa84059fc2",
              "IPY_MODEL_4f367185c50c405fb6f8561a50549b55",
              "IPY_MODEL_847d33ebd71a454d8938bc0457c74fb3"
            ],
            "layout": "IPY_MODEL_94b7c159a3374c72b0e0e24bbb9a8345"
          }
        },
        "e1f4fc89d0fd41f9bf8573fa84059fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a79a28ce690d410b8fccaffd9cdc3e96",
            "placeholder": "​",
            "style": "IPY_MODEL_253d76e2b6954744abcfcf25a8c2d18e",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "4f367185c50c405fb6f8561a50549b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48c972e27167450588b34ad82854dd9f",
            "max": 775,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_471b4733897447aeb1b7a52afc55971f",
            "value": 775
          }
        },
        "847d33ebd71a454d8938bc0457c74fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d026443bd4e4a01acc0cf57f34479cf",
            "placeholder": "​",
            "style": "IPY_MODEL_a8b1038686b341fdaa6db9a2461df170",
            "value": " 775/775 [00:00&lt;00:00, 7.10kB/s]"
          }
        },
        "94b7c159a3374c72b0e0e24bbb9a8345": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a79a28ce690d410b8fccaffd9cdc3e96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "253d76e2b6954744abcfcf25a8c2d18e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48c972e27167450588b34ad82854dd9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "471b4733897447aeb1b7a52afc55971f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d026443bd4e4a01acc0cf57f34479cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8b1038686b341fdaa6db9a2461df170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ec5103d14474809b3dabf462d605fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9385ae891a114cbebcad517e20312759",
              "IPY_MODEL_8f7c69f798294c66b8492967b2c62041",
              "IPY_MODEL_9bbc68861f074e4b9337fb6b48ca76d1"
            ],
            "layout": "IPY_MODEL_64145a4aa0754c52aae89e7163f6f0e7"
          }
        },
        "9385ae891a114cbebcad517e20312759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3f8ae7c6c1742f48d9f4b1c1ff5f394",
            "placeholder": "​",
            "style": "IPY_MODEL_cf8f947551c64073945c3bc906c95ab2",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "8f7c69f798294c66b8492967b2c62041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_067fc824211848a29f85b0ef7a283887",
            "max": 512568261,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b248350962f0446aab49ad51f3d99dd3",
            "value": 512568261
          }
        },
        "9bbc68861f074e4b9337fb6b48ca76d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c05e45064fb4aca9d8aee901c117476",
            "placeholder": "​",
            "style": "IPY_MODEL_e0a79bb68700458b8039605af12c5197",
            "value": " 513M/513M [00:27&lt;00:00, 19.7MB/s]"
          }
        },
        "64145a4aa0754c52aae89e7163f6f0e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3f8ae7c6c1742f48d9f4b1c1ff5f394": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf8f947551c64073945c3bc906c95ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "067fc824211848a29f85b0ef7a283887": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b248350962f0446aab49ad51f3d99dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c05e45064fb4aca9d8aee901c117476": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0a79bb68700458b8039605af12c5197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}